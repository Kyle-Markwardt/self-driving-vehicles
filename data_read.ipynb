{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e80e5fd-6901-4cbe-a616-23e84bbce0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is the code I used to poke at the values within the Disengagement Description\\nvc = combined_dis_df['Disengagement Description'].value_counts()\\ncounter = 0\\nfor i in range(10):\\n    print(vc[i])\\n    counter += vc[i]\\nprint()\\nprint(counter)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import pprint as pprint\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#Notes for K.  \n",
    "# 1. In combined_dis_df I've simplified the column names.  I observed your VSC terminal was autofilling these in.  Let's observe how it reacts to\n",
    "#.   this change?  Does it automatically update the code you've written in main that references the old column names?  We can revert this change \n",
    "#.   simply, by commenting the column name changes out.\n",
    "\n",
    "#ToDos\n",
    "# 1. Write output .csv for combined disengagement reports\n",
    "\n",
    "#More Complex ToDos\n",
    "#1.  Restructure these things as a function, which can pass data to main?  Or is it better for these things to produce an output csv that main can\n",
    "#.    then read?  Does size matter for this sort of thing?  Like, with 20k rows etc, is there a best practices?\n",
    "\n",
    "# Notes to recall a/b data\n",
    "# 1. There is no 2022 driverless disengagement report.  2020-21 and 2023 combined are 18 rows.  Does this seem strange?  \n",
    "# 2. If we accept the driverless disengagement at face value, there were startingly few disengagements in NVO mode.  How does this correlate to NVO miles?\n",
    "# 3. There are only 6 disengagement reports for \"Parking Facilities\".  Given the amount of testing that (presumably) occured in parking lots\n",
    "#.  And parking Garages, I'm inclined to think that these generally didn't result in reports to the state.  \n",
    "# 4.  There are 904 distinct reasons for disengagement.  This disengagement report has 17.7k items.  \n",
    "#.    The top 10 of these account for 10k of the descriptions.  The top 3 account for 5.8k.  The top 5, 7.8k\n",
    "# 5.  There's no way Cruise had so few disengagements\n",
    "\n",
    "'''\n",
    "This is the code I used to poke at the values within the Disengagement Description\n",
    "vc = combined_dis_df['Disengagement Description'].value_counts()\n",
    "counter = 0\n",
    "for i in range(10):\n",
    "    print(vc[i])\n",
    "    counter += vc[i]\n",
    "print()\n",
    "print(counter)\n",
    "'''\n",
    "\n",
    "#Questions\n",
    "# 1. I am unsure of when to use inplace=True .  When is appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed85915-c779-48bc-99d5-d143073be8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists used by K to assist read in.  Monthly list used for simplified mileage reports\n",
    "years = [\"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "years = sorted(list(years))\n",
    "\n",
    "months = [\"DEC-1\", \"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JULY\", \"AUG\", \"SEP\", \"OCT\", \"NOV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b32dab-4bd6-4aca-8ed7-2489afc38631",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in disengagements data, dropping null rows & columns\n",
    "# Yearly disengagement \n",
    "# These are all reading in correctly\n",
    "\n",
    "dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        #print(f\"Type 1 File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='latin-1')\n",
    "    dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "disengagement_df = pd.concat(dis_dfs, ignore_index=True)\n",
    "\n",
    "# 1st time disengagement reports\n",
    "first_time_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        #print(f\"Type 2 File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='latin-1')\n",
    "    first_time_dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "first_df = pd.concat(first_time_dis_dfs, ignore_index=True)\n",
    "\n",
    "# Driverless reports.  2022 is missing.  There are only 2 files here.  \n",
    "# I've combined the above 2x for loops to snag them both,since the files have different naming conventions\n",
    "driverless_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        #print(f\"Type 3a File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "for year in years:    \n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "        # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        #print(f\"Type 3b File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "        # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "autonomous_dis_df = pd.concat(driverless_dis_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c85f72-0d92-48e3-a51d-5f12a92db9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining 3x disengagement DFs into a single DF.  They all have same column names, withh one report having an additional column.\n",
    "# 3x active DFs for the disengagement info are\n",
    "# disengagement_df\n",
    "# first_df\n",
    "# autonomous_dis_df\n",
    "\n",
    "disengagement_dfs_list = [disengagement_df, first_df, autonomous_dis_df]\n",
    "combined_dis_df = pd.concat(disengagement_dfs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea6ebf5-9e67-4c6a-a215-a50dcb9e6169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Cleaning combined_dis_DF\n",
    "\n",
    "# The unnamed column 10 only appears in the 2021 report, and the 71 entries are all for IMAGRY INC., reading \"Perception\" or \"Planning\"\n",
    "# Dropped Column\n",
    "# Try is used to allow the block to be re-run without generating an error, or the need to rerun above blocks\n",
    "\n",
    "try:\n",
    "    combined_dis_df = combined_dis_df.drop('Unnamed: 9', axis=1)\n",
    "except KeyError:\n",
    "    print(\"Column 'Unnamed: 9' already dropped\")\n",
    "\n",
    "# Dropped 9k+ null rows\n",
    "combined_dis_df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# Updating column names\n",
    "new_combined_dis_df_column_names = ['Company', 'Permit #', 'Date', 'VIN', 'Driverless Capable', 'Driver Present', 'Disengagement Initiation', \n",
    "                                    'Disengagement Location', 'Disengagement Description']\n",
    "combined_dis_df.columns = new_combined_dis_df_column_names\n",
    "\n",
    "# Dropping time from DATE column (some limited % of entries include this), converting to_datetime\n",
    "# Could these further be combined into one line?  Where can I learn more a/b this?\n",
    "combined_dis_df['Date'] = combined_dis_df['Date'].astype(str).str.split(\" \", expand=True)[0]\n",
    "combined_dis_df['Date'] = pd.to_datetime(combined_dis_df['Date'], errors='raise', dayfirst=True, format='mixed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52bac76c-b903-4db8-a4ce-70cd5c8fafec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Cleaning up combined_dis_df\n",
    "## Unifying text format, all except last column (descriptions), and skipping over Date column via try/except\n",
    "# Strip any spaces at the start or end, .upper, \n",
    "for i in combined_dis_df.iloc[:,:-1]:\n",
    "    #print(\"Column stripped & upper: \" + i)\n",
    "    try:\n",
    "        combined_dis_df[i] = combined_dis_df[i].str.strip()\n",
    "        combined_dis_df[i]= combined_dis_df[i].str.upper()\n",
    "    except AttributeError:\n",
    "        continue\n",
    "\n",
    "#Cleaning 'Disengagement Initiation\n",
    "combined_dis_df['Disengagement Initiation'] = combined_dis_df['Disengagement Initiation'].str.replace(r'^TEST DRIVER - SOFT STOP$', 'TEST DRIVER', regex=True)\n",
    "combined_dis_df['Disengagement Initiation'] = combined_dis_df['Disengagement Initiation'].str.replace(r'^AV SYSTEM - EMERGENCY STOP$', 'AV SYSTEM', regex=True)\n",
    "combined_dis_df['Disengagement Initiation'] = combined_dis_df['Disengagement Initiation'].str.replace(r'^TEST DRIVE$', 'TEST DRIVER', regex=True)\n",
    "combined_dis_df['Disengagement Initiation'] = combined_dis_df['Disengagement Initiation'].str.replace(r'^DRIVER$', 'TEST DRIVER', regex=True)\n",
    "combined_dis_df['Disengagement Initiation'] = combined_dis_df['Disengagement Initiation'].str.replace(r'^SOFTWARE$', 'AV SYSTEM', regex=True)\n",
    "combined_dis_df['Disengagement Initiation'] = combined_dis_df['Disengagement Initiation'].str.replace(r'^ADS$', 'AV SYSTEM', regex=True)\n",
    "combined_dis_df['Disengagement Initiation'] = combined_dis_df['Disengagement Initiation'].str.replace(r'^OPERATOR$', 'TEST DRIVER', regex=True)\n",
    "combined_dis_df['Disengagement Initiation'].value_counts()\n",
    "\n",
    "## Cleaning 'Company'\n",
    "# Dropping all words after the first word in 'Company', dropping all commas left floating at the end, capitlizing all words.\n",
    "combined_dis_df[\"Company\"] = combined_dis_df[\"Company\"].str.upper().str.split(\" \", expand=True)[0].str.replace(\",\", \"\")\n",
    "\n",
    "## Cleaning 'Disengagement Location'\n",
    "# Freeway has a technical definition (it's free) vs Toll Road (paid).  \n",
    "# Highway usually references state funded 'interstate' style roads, whereas Interstates are federally funded\n",
    "# Express-Way is a subset of Toll Roads, referencing less exits and segregated lanes.\n",
    "# Regardless, I've combined these all into \"Highway\" so the contrast b/t 'Street' is clear.  These different types of high traffick roads are\n",
    "#   a mish-mash in the Bay Area and LA, and nothing indicates these distinctions were used with percision (colliqually they are almost never) or that\n",
    "#   even if they were, it would matter to our analysis\n",
    "# Also combined \"Urban\" into \"Street\"\n",
    "combined_dis_df['Disengagement Location'] = combined_dis_df['Disengagement Location'].str.upper()\n",
    "combined_dis_df['Disengagement Location'] = combined_dis_df['Disengagement Location'].str.replace(\"FREEWAY \", \"FREEWAY\")\n",
    "combined_dis_df['Disengagement Location'] = combined_dis_df['Disengagement Location'].str.replace(\"FREEWAY\", \"HIGHWAY\")\n",
    "combined_dis_df['Disengagement Location'] = combined_dis_df['Disengagement Location'].str.replace(\"EXPRESS WAY\", \"HIGHWAY\")\n",
    "combined_dis_df['Disengagement Location'] = combined_dis_df['Disengagement Location'].str.replace(\"INTERSTATE\", \"HIGHWAY\")\n",
    "combined_dis_df['Disengagement Location'] = combined_dis_df['Disengagement Location'].str.replace(\"URBAN\", \"STREET\")\n",
    "\n",
    "## Cleaning up a tricky problem in VINs.  See below cell for code used to ID and isolate problem\n",
    "#This code captures all the unique 5 letter vins, drops the ~, \n",
    "unique_vin_4_letter_list = set(list(combined_dis_df.loc[combined_dis_df['VIN'].str.contains('~')]['VIN'].str.replace(\"~\", \"\")))\n",
    "zoox_vin_17_character_list = set(list(combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.len() == 17)]['VIN']))\n",
    "\n",
    "#This nested for loop checks to see which nnnn's are a subset of a full VIN, and then replaces all instances with that nnnn w/ the full VIN\n",
    "for i in unique_vin_4_letter_list:\n",
    "    for j in zoox_vin_17_character_list:\n",
    "        if str(i) in str(j):\n",
    "            combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.contains(i)), 'VIN'] = j\n",
    "            #print(combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.contains(i))]['VIN'])\n",
    "\n",
    "# This code confirms 2 of the unique ~nnnn VINs have been replaced.  \n",
    "# Length of 19 prints, instead of 21 in original set(list) .  23 values in in total entry list, instead of 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4731dd2-bb6d-4fef-8e04-f29d76178130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## Data Quality inspection post-cleanup.  All nice and pretty.  Remove  to run and confirm clean data.\\n# VIN Cleanup Status\\nvin_length_check = set(list(combined_dis_df[\\'VIN\\'].str.len().sort_values()))\\nprint(f\"VIN contains strings of length: {vin_length_check}\")\\nvin_5_letter_list = combined_dis_df.loc[combined_dis_df[\\'VIN\\'].str.len() == 5, \\'VIN\\']\\n#[vin for vin in vin_list if len(vin)==5]\\nvin_18_letter_list = combined_dis_df.loc[combined_dis_df[\\'VIN\\'].str.len() == 18, \\'VIN\\']\\nprint(f\"There are {len(vin_5_letter_list)} 5 letter VINs. \\n There are {len(set(list(vin_5_letter_list)))} unique 5 letter VINs. \\n They are {(set(list(vin_5_letter_list)))}\")\\nprint()\\nprint(f\"There are {len(vin_18_letter_list)} 18 letter VINs. \\n There are {len(set(list(vin_18_letter_list)))} unique 18 letter VINs. \\n They are {set(list(vin_18_letter_list))}\")\\nprint(\"\\n Space Break \\n\")\\n\\n# Review all columns value_counts, verify they\\'re cleaned\\nfor i in combined_dis_df:\\n    print(combined_dis_df[i].value_counts())\\n    print(\"\\n SPACE BREAK \\n\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## Data Quality inspection post-cleanup.  All nice and pretty.  Remove ''' ''' to run and confirm clean data.\n",
    "# VIN Cleanup Status\n",
    "vin_length_check = set(list(combined_dis_df['VIN'].str.len().sort_values()))\n",
    "print(f\"VIN contains strings of length: {vin_length_check}\")\n",
    "vin_5_letter_list = combined_dis_df.loc[combined_dis_df['VIN'].str.len() == 5, 'VIN']\n",
    "#[vin for vin in vin_list if len(vin)==5]\n",
    "vin_18_letter_list = combined_dis_df.loc[combined_dis_df['VIN'].str.len() == 18, 'VIN']\n",
    "print(f\"There are {len(vin_5_letter_list)} 5 letter VINs. \\n There are {len(set(list(vin_5_letter_list)))} unique 5 letter VINs. \\n They are {(set(list(vin_5_letter_list)))}\")\n",
    "print()\n",
    "print(f\"There are {len(vin_18_letter_list)} 18 letter VINs. \\n There are {len(set(list(vin_18_letter_list)))} unique 18 letter VINs. \\n They are {set(list(vin_18_letter_list))}\")\n",
    "print(\"\\n Space Break \\n\")\n",
    "\n",
    "# Review all columns value_counts, verify they're cleaned\n",
    "for i in combined_dis_df:\n",
    "    print(combined_dis_df[i].value_counts())\n",
    "    print(\"\\n SPACE BREAK \\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f58d5bb-d32e-4905-beb0-d1e4c695d92e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values is: 0\n",
      "Number of null values is: 0\n",
      "Number of null values is: 0\n",
      "(1174, 17)\n",
      "(1553, 17)\n",
      "(1603, 17)\n",
      "\n",
      "Index(['2021 Manufacturer', '2021 Permit Number', '2021 VIN',\n",
      "       '2021 Total Disengagements', '2020 DEC', '2021 JAN', '2021 FEB',\n",
      "       '2021 MAR', '2021 APR', '2021 MAY', '2021 JUN', '2021 JUL', '2021 AUG',\n",
      "       '2021 SEP', '2021 OCT', '2021 NOV',\n",
      "       '2020 DEC - 2021 NOV Mileagle Total', '2022 Manufacturer',\n",
      "       '2022 Permit Number', '2022 VIN', '2022 Total Disengagements',\n",
      "       '2021 DEC', '2022 JAN', '2022 FEB', '2022 MAR', '2022 APR', '2022 MAY',\n",
      "       '2022 JUN', '2022 JUL', '2022 AUG', '2022 SEP', '2022 OCT', '2022 NOV',\n",
      "       '2021 DEC - 2022 NOV Mileagle Total', '2023 Manufacturer',\n",
      "       '2023 Permit Number', '2023 VIN', '2023 Total Disengagements',\n",
      "       '2022 DEC', '2023 JAN', '2023 FEB', '2023 MAR', '2023 APR', '2023 MAY',\n",
      "       '2023 JUN', '2023 JUL', '2023 AUG', '2023 SEP', '2023 OCT', '2023 NOV',\n",
      "       '2022 DEC - 2023 NOV Mileagle Total'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### MILEAGE REPORTS\n",
    "\n",
    "## K's original mile_dfs readin AND mileage_df .  Leaving here so as to not throw off any of K's charts in main.\n",
    "mile_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        #print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='latin-1')\n",
    "    annual_mileage[\"Year\"] = year\n",
    "    annual_mileage.rename(columns={'ANNUAL TOTAL': 'Mileage Total'}, inplace=True)\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_mileage.columns.values[i] = month\n",
    "    mile_dfs.append(annual_mileage)\n",
    "    # INFO: each annual report has 22 cols\n",
    "\n",
    "mileage_df = pd.concat(mile_dfs, ignore_index=True)\n",
    "# mileage_df.set_index('VIN NUMBER', inplace=True)\n",
    "#mileage_df['VIN NUMBER'].value_counts()\n",
    "\n",
    "    \n",
    "## New version, designed for joining to create multi-year M/m columns.  JULY is now JUL\n",
    "new_mile_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        #print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='latin-1')\n",
    "    annual_mileage.rename(columns={'Manufacturer': f\"{year} Manufacturer\"}, inplace=True)\n",
    "    annual_mileage.rename(columns={'Permit Number': f\"{year} Permit Number\"}, inplace=True)\n",
    "    \n",
    "    #Dropping rows based on empty VIN, before changing name.  Can't get it to work dynamically\n",
    "    # Took several tries, adding how and inplace, to make it stack\n",
    "    annual_mileage.dropna(subset = ['VIN NUMBER'], how='any', inplace=True)\n",
    "    print('Number of null values is: ' + str(annual_mileage['VIN NUMBER'].isnull().sum()))\n",
    "    \n",
    "    annual_mileage.rename(columns={'VIN NUMBER': f\"{year} VIN\"}, inplace=True)\n",
    "    annual_mileage.rename(columns={'Annual Total of Disengagements': f\"{year} Total Disengagements\"}, inplace=True)\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_mileage.columns.values[i] = (f\"{annual_mileage.columns.values[i][-4:]} {annual_mileage.columns.values[i][:3]}\")\n",
    "    annual_mileage.rename(columns={'ANNUAL TOTAL': f\"{str(int(year) - 1)} DEC - {year} NOV Mileagle Total\"}, inplace=True)\n",
    "    unnamed_cols = ['Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21']\n",
    "    annual_mileage= annual_mileage.drop(columns=unnamed_cols)\n",
    "    new_mile_dfs.append(annual_mileage)\n",
    "    #print(annual_mileage.columns.values)\n",
    "\n",
    "#Want to learn how to do a join instead\n",
    "new_mileage_df = pd.concat(new_mile_dfs, ignore_index=True)\n",
    "for i in new_mile_dfs:\n",
    "    print(i.shape)\n",
    "print()\n",
    "print(new_mileage_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbadb1c3-0ea3-4f54-94f1-dd37a24d42d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174\n",
      "['JTDKN3DU9A0059509' '4T1B21HK6KU514747' '3LN6L5LU2HR615153'\n",
      " '3LN6L2LU4GR629715' '3LN6L5LU1HR627987' '3LN6L2LU5GR607996'\n",
      " '2T2BGMCA5JC021381' '2T2BGMCA0GC007400' '2T2BGMCA0HC014753'\n",
      " '2T2BGMCA0HC016082']\n",
      "\n",
      "1174\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m vin_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m vin_counter \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(new_mileage_df[new_mileage_df\u001b[38;5;241m.\u001b[39miloc[new_mileage_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021 VIN\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mvins_2021[vin_counter]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021 Manufacturer\u001b[39m\u001b[38;5;124m'\u001b[39m]]])\n\u001b[1;32m     20\u001b[0m     vin_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "#When these print checks are cleaned up, they can be reduced to a sentence or two of output that verifies no duplicate VINs in a year, etc\n",
    "\n",
    "vin_check_placeholder = []\n",
    "vins_2021 = pd.unique(new_mileage_df['2021 VIN'])                          \n",
    "#vins_2022 = set(list(new_mileage_df.loc[new_mileage_df['2022 VIN']]))\n",
    "#vins_2023 = set(list(new_mileage_df.loc[new_mileage_df['2023 VIN']]))\n",
    "\n",
    "print(len(vins_2021))\n",
    "#print(len(vins_2022))\n",
    "#print(len(vins_2023))\n",
    "print(vins_2021[:10])\n",
    "print()\n",
    "vins_check_placeholder= set(list(vins_2021))\n",
    "print(len(vins_check_placeholder))\n",
    "print()\n",
    "\n",
    "vin_counter = 0\n",
    "while vin_counter < 10:\n",
    "    print(new_mileage_df[new_mileage_df.iloc[new_mileage_df['2021 VIN']==vins_2021[vin_counter].loc['2021 Manufacturer']]])\n",
    "    vin_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "459e400e-0714-4e4f-af5f-b427336a8220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non values in 2021 VIN: 1174\n",
      "Number of non values in 2022 VIN: 1553\n",
      "Number of non values in 2023 VIN: 1603\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[704], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of non values in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheck\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnon_null_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m new_mileage_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021 VIN\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m element[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021 VIN\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(new_mileage_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021 VIN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021 Manufacturer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "vin_col = ['2021 VIN', '2022 VIN', '2023 VIN']\n",
    "for check in vin_col:\n",
    "    non_null_count = new_mileage_df[check].notna().sum()\n",
    "    print(f'Number of non values in {check}: {non_null_count}')\n",
    "    \n",
    "for i in new_mileage_df['2021 VIN']:\n",
    "    if element['2021 VIN'].notna() == True:\n",
    "        print(new_mileage_df.loc['2021 VIN', '2021 Manufacturer'])\n",
    "    else:\n",
    "        continue\n",
    "   #Dataframe2[Dateframe2.Column2.isin([element])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "1740c900-0437-490d-b187-8345d780546e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2021 VIN</th>\n",
       "      <th>2022 VIN</th>\n",
       "      <th>2023 VIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~8547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~9098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~4787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~8508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~6969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~6099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~6573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~7397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~5151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~1771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~4430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~4557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~9639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~7211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~6888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~2949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~3480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~9121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2021 VIN 2022 VIN 2023 VIN\n",
       "4299      NaN      NaN    ~1655\n",
       "4300      NaN      NaN    ~7590\n",
       "4301      NaN      NaN    ~4530\n",
       "4302      NaN      NaN    ~8547\n",
       "4303      NaN      NaN    ~9098\n",
       "4304      NaN      NaN    ~4787\n",
       "4305      NaN      NaN    ~2865\n",
       "4306      NaN      NaN    ~8508\n",
       "4307      NaN      NaN    ~6969\n",
       "4308      NaN      NaN    ~4153\n",
       "4309      NaN      NaN    ~6099\n",
       "4310      NaN      NaN    ~6573\n",
       "4311      NaN      NaN    ~7397\n",
       "4312      NaN      NaN    ~5151\n",
       "4313      NaN      NaN    ~9765\n",
       "4314      NaN      NaN    ~1771\n",
       "4315      NaN      NaN    ~4430\n",
       "4316      NaN      NaN    ~5396\n",
       "4317      NaN      NaN    ~0971\n",
       "4318      NaN      NaN    ~1299\n",
       "4319      NaN      NaN    ~4557\n",
       "4320      NaN      NaN    ~9639\n",
       "4321      NaN      NaN    ~7211\n",
       "4322      NaN      NaN    ~2856\n",
       "4323      NaN      NaN    ~6888\n",
       "4324      NaN      NaN    ~2949\n",
       "4325      NaN      NaN    ~1098\n",
       "4326      NaN      NaN    ~0868\n",
       "4327      NaN      NaN    ~3480\n",
       "4328      NaN      NaN    ~3875\n",
       "4329      NaN      NaN    ~9121"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mileage_df.loc[:,['2021 VIN', '2022 VIN', '2023 VIN']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "48214a3e-b0a1-40e0-b6be-3236f8987182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.where(df['Level'] == 0, df['Item'], df['Item'].shift()\n",
    "# Checking VINs to Manufacturer\n",
    "# I think there might be an easier way to do this\n",
    "#np.where(new_mileage_df.loc['2021 VIN']\n",
    "         \n",
    "#new_mileage_df.dtypes\n",
    "# Going to have to break down and use a list and a for loop\n",
    "#new_mileage_df.loc[new_mileage_df['2021 VIN'], '2021 Manufacturer']\n",
    "\n",
    "vin_2021 = set(list(new_mileage_df.loc[new_mileage_df['2021 VIN'].notna()]))\n",
    "len(vin_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f85a62-6fef-4148-bfee-d0ef78bfe1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_count = mileage_df[check].notna()\n",
    "\n",
    "unique_vin_4_letter_list = set(list(combined_dis_df.loc[combined_dis_df['VIN'].str.contains('~')]['VIN'].str.replace(\"~\", \"\")))\n",
    "zoox_vin_17_character_list = set(list(combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.len() == 17)]['VIN']))\n",
    "\n",
    "#This nested for loop checks to see which nnnn's are a subset of a full VIN, and then replaces all instances with that nnnn w/ the full VIN\n",
    "for i in unique_vin_4_letter_list:\n",
    "    for j in zoox_vin_17_character_list:\n",
    "        if str(i) in str(j):\n",
    "            combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.contains(i)), 'VIN'] = j\n",
    "            #print(combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.contains(i))]['VIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a804e-4af0-4779-a046-9ea4a29a0462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "### Details on how I tracked down & issolated the VIN issue\n",
    "## VINs should all be 17 letters long, per this link:  https://www.autocheck.com/vehiclehistory/vin-basics\n",
    "#This line of code prints a preview, showing 3x VINs 18 characters long, and some unknown # of VINs 5 characters long\n",
    "combined_dis_df['VIN'].str.len().sort_values()\n",
    "\n",
    "#These lines ID that the column only contains elements 5, 17, or 18 characters long\n",
    "vin_length_check = []\n",
    "vin_length_check = set(list(combined_dis_df['VIN'].str.len().sort_values()))\n",
    "print(vin_length_check)\n",
    "\n",
    "#These lines sort them out.  The 18 letter VIN has 1 number too many at the end, and is repeated 3 times.  \n",
    "vin_list = []\n",
    "vin_list = combined_dis_df['VIN']\n",
    "vin_5_letter_list = [vin for vin in vin_list if len(vin)==5]\n",
    "vin_18_letter_list = [vin for vin in vin_list if len(vin)==18]\n",
    "print(f\"There are {len(vin_5_letter_list)} 5 letter VINs. \\n There are {len(set(list(vin_5_letter_list)))} unique 5 letter VINs. \\n They are {(set(list(vin_5_letter_list)))}\")\n",
    "print()\n",
    "print(f\"There are {len(vin_18_letter_list)} 18 letter VINs. \\n There are {len(set(list(vin_18_letter_list)))} unique 18 letter VINs. \\n They are {set(list(vin_18_letter_list))}\")\n",
    "print(\"\\n Space Break \\n\")\n",
    "\n",
    "#This searches the column for the first portion of the VIN, w/o the numbers at the end.  Nothing new turned up.  Same 3x entries.\n",
    "# The 18 letter VINs - 3LN6L5LU6HR6267668 - is a Pony.AI car.  All 3 come from the 2021-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\n",
    "# The 5 letter VINs all begin with ~ .  They are all from ZOOX, 2022 and 2023 reports of the same name.\n",
    "print(combined_dis_df.loc[combined_dis_df['VIN'].str.contains('3LN6L5LU6HR')])\n",
    "print(\"\\n SPACE BREAK \\n\")\n",
    "print(combined_dis_df.loc[combined_dis_df['VIN'].str.contains('~')])\n",
    "\n",
    "# Will keep an eye out for this 18 character VIN and its substrings in the mileage report, also the ~nnnn's\n",
    "\n",
    "#This shows us all the ZOOX lines w/ VIN.  Some VINs are full, others not. Apx 40 total lines.  \n",
    "# The ~nnnn that have a previous full entry can be inferred, but most don't have a previous entry\n",
    "print(combined_dis_df.loc[combined_dis_df['Company'].str.contains('ZOOX'), ['Company', 'VIN']])\n",
    "\n",
    "### THIS BELOW CODE IS IN USE\n",
    "#This code captures all the unique 5 letter vins, drops the ~, \n",
    "unique_vin_4_letter_list = set(list(combined_dis_df.loc[combined_dis_df['VIN'].str.contains('~')]['VIN'].str.replace(\"~\", \"\")))\n",
    "zoox_vin_17_character_list = set(list(combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.len() == 17)]['VIN']))\n",
    "\n",
    "#This nested for loop checks to see which nnnn's are a subset of a full VIN, and then replaces all instances with that nnnn w/ the full VIN\n",
    "for i in unique_vin_4_letter_list:\n",
    "    for j in zoox_vin_17_character_list:\n",
    "        if str(i) in str(j):\n",
    "            combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.contains(i)), 'VIN'] = j\n",
    "            print(combined_dis_df.loc[(combined_dis_df[\"Company\"] == 'ZOOX') & (combined_dis_df[\"VIN\"].str.contains(i))]['VIN'])\n",
    "\n",
    "# This code confirms 2 of the unique ~nnnn VINs have been replaced.  \n",
    "# Length of 19 prints, instead of 21 in original set(list) .  23 values in in total entry list, instead of 25\n",
    "### THIS ABOVE CODE IS IN USE\n",
    "\n",
    "unique_vin_4_letter_list_CHECKER = set(list(combined_dis_df.loc[combined_dis_df['VIN'].str.contains('~')]['VIN']))\n",
    "print(len(unique_vin_4_letter_list_CHECKER))\n",
    "vin_list_post_cleanup = []\n",
    "vin_list_post_cleanup = combined_dis_df['VIN']\n",
    "vin_5_letter_list_post_cleanup = [vin for vin in vin_list_post_cleanup if len(vin)==5]\n",
    "print(len(vin_5_letter_list))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf341346-514e-4ad5-976b-28a1fc13ef3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
