{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8af4c23",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff662bd6-1e47-43a8-924f-3f1a7c45d0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "from bokeh.io import output_notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b09241",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb78dc-84c3-4932-962c-ae8f7db5c475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Lists\n",
    "## Years common across data\n",
    "years = [\"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "years = sorted(list(years))\n",
    "\n",
    "months = [\"DEC-1\", \"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JULY\", \"AUG\", \"SEP\", \"OCT\", \"NOV\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d2e0f",
   "metadata": {},
   "source": [
    "### Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9017a-6e18-47f0-960f-9a8f7b73a72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Read in mileage data\n",
    "mile_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='latin-1')\n",
    "    annual_mileage[\"Year\"] = year\n",
    "    annual_mileage.rename(columns={'ANNUAL TOTAL': 'Mileage Total'}, inplace=True)\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_mileage.columns.values[i] = month\n",
    "    mile_dfs.append(annual_mileage)\n",
    "    # INFO: each annual report has 22 cols\n",
    "\n",
    "mileage_df = pd.concat(mile_dfs, ignore_index=True)\n",
    "# mileage_df.set_index('VIN NUMBER', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "miles_sum_list = ['DEC-1','JAN','FEB','MAR','APR','MAY','JUN','JULY','AUG','SEP','OCT','NOV']\n",
    "\n",
    "miles_sum = mileage_df[miles_sum_list].sum(axis=1)\n",
    "\n",
    "print(miles_sum.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548203a",
   "metadata": {},
   "source": [
    "First Time Filers - Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb7046-df7d-49fa-b0c9-4c4db90f9c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mile_first_time_filer_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-first-time-filers.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-first-time-filers.csv\", encoding='latin-1')\n",
    "    mile_first_time_filer_dfs.append(annual_disengagements)\n",
    "    \n",
    "# Not combining due to join issue raised at top of document\n",
    "#first_time_mileage_df = pd.concat(mile_first_time_filer, ignore_index=True)\n",
    "\n",
    "#print(mile_first_time_filer_dfs[0].head())\n",
    "print(\"# of objects in mile_driverless_dfs:  \" + str(len(mile_first_time_filer_dfs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21ac82",
   "metadata": {},
   "source": [
    "Driverless Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c52ee2-eab0-4c3d-ad82-9d282275f540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DB - Using the same process I used above, for Autonomous-Mileage-Reports-CSV-driverless.csv & Autonomous-Mileage-Reports-CSV-first-time-filers.csv\n",
    "mile_driverless_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    annual_disengagements[\"Year\"] = year\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_disengagements.columns.values[i] = month\n",
    "    mile_driverless_dfs.append(annual_disengagements)\n",
    "\n",
    "for year in years:    \n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "        # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "        # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    annual_disengagements[\"Year\"] = year\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_disengagements.columns.values[i] = month\n",
    "    mile_driverless_dfs.append(annual_disengagements)\n",
    "\n",
    "driverless_mileage_df = pd.concat(mile_driverless_dfs, ignore_index=True)\n",
    "# TODO: deal with stupid double year file.\n",
    "\n",
    "#print(mile_driverless_dfs[0].head())\n",
    "print(\"# of objects in mile_driverless_dfs:  \" + str(len(mile_driverless_dfs)))\n",
    "driverless_mileage_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7ea68",
   "metadata": {},
   "source": [
    "Combined Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Duplicate and modify code from combined disengagements here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89e2e7",
   "metadata": {},
   "source": [
    "### Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf860b08-a42c-4174-bc47-a0af44cc4340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Read in data\n",
    "## Read in disengagements data\n",
    "dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='latin-1')\n",
    "    dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "disengagement_df = pd.concat(dis_dfs, ignore_index=True)\n",
    "\n",
    "#DB.  The unnamed column 10 only appears in the 2021 report, and the 71 entries are all for IMAGRY INC.,\n",
    "# Reading \"Perception\" or \"Planning\"\n",
    "# Dropped Column\n",
    "disengagement_df = disengagement_df.drop('Unnamed: 9', axis=1)\n",
    "#Apx 8k  empty rows.  Droped all rows with any nulls.  \n",
    "disengagement_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8da44d",
   "metadata": {},
   "source": [
    "First Time Filers - Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369e28f-3b82-4c99-aa33-acecabe5c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding in 1st time filer Disengagements.  Utilizing Kyle's code from above\n",
    "first_time_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='latin-1')\n",
    "    first_time_dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "first_df = pd.concat(first_time_dis_dfs, ignore_index=True)\n",
    "#Some 200ish null rows imported. Dropped any row with any missing data\n",
    "first_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45e32e",
   "metadata": {},
   "source": [
    "Driverless Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccbe32-7977-4e1b-9395-91ed1b109269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Driverless reports.  2022 is missing.  There are only 2 files here.  I've combined the above 2x for loops to snag them both, \n",
    "# since they have different naming conventions\n",
    "driverless_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "for year in years:    \n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "        # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "        # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "autonomous_dis_df = pd.concat(driverless_dis_dfs, ignore_index=True)\n",
    "# Dropping some 2000+ null rows.\n",
    "autonomous_dis_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748786cc",
   "metadata": {},
   "source": [
    "Combined Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf3fc9-c6ef-4a7d-8521-ee5066cf226b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3x active DFs for the disengagement info are\n",
    "# disengagement_df\n",
    "# first_df\n",
    "# autonomous_dis_df\n",
    "# List of these objects to for loop the DATE cleanup.  \n",
    "# IF we wanted to acccess the report source from the combined df, we could add a column to each, with the report source\n",
    "\n",
    "# Initially had trouble by converting the dates to_datetime and then trying to drop the hour/min/sec.\n",
    "# Resolved by first converting DATE to str, dropping everything after \" \" (since all times were separated from date by a space)\n",
    "# And then subsequently converting the column to_datetime\n",
    "\n",
    "# This works, but can't be re-run unless above code blocks that create the dfs are also re-run (I think).  \n",
    "# Used print(i['DATE'].value_counts()) to confirm this came out correctly.  \n",
    "\n",
    "disengagement_dfs_list = [disengagement_df, first_df, autonomous_dis_df]\n",
    "\n",
    "for i in disengagement_dfs_list:\n",
    "    i['DATE'] = i['DATE'].astype(str)\n",
    "    i[\"DATE\"] = i[\"DATE\"].str.split(\" \", expand=True)[0]\n",
    "    i['DATE'] = pd.to_datetime(i['DATE'], errors='raise', dayfirst=True, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279e6c6-8311-416c-9da4-1f00ffe034fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for i in disengagement_dfs_list:\n",
    "    #print(i['Permit Number'].value_counts())\n",
    "    print(i.shape)\n",
    "'''\n",
    "\n",
    "# Operator-in-Vehicle = AVT Permit prefix\n",
    "# NVO = AVDT Permit Prefix.\n",
    "# I'm fairly certain splitting these into distinct columns for purposes of multi-indexed rows or columns is straightforward, \n",
    "# So am moving forward with data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c862d-6ec4-4539-885c-530250ea8b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3x disengagement df's combined together into one, single column for all permit info\n",
    "combined_dis_df = pd.concat(disengagement_dfs_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481e0a0",
   "metadata": {},
   "source": [
    "# Data Cleaning and QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f17631",
   "metadata": {},
   "source": [
    "Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are \"Unnamed\" colums? Probably useless \"reserved\"\n",
    "# This and below are from kyle, and deal with the initial mileage_df\n",
    "unnamed_cols = ['Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21']\n",
    "for check in unnamed_cols:\n",
    "    non_null_count = mileage_df[check].notna().sum()\n",
    "    print(f'Number of non values in {check}: {non_null_count}')\n",
    "\n",
    "# Empty. Drop 'em\n",
    "mileage_df = mileage_df.drop(columns=unnamed_cols)\n",
    "mileage_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e09a3",
   "metadata": {},
   "source": [
    "Set Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcaf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mileage\n",
    "print(f'Before: {mileage_df.dtypes}')\n",
    "cast_as_float = [\n",
    "       'Annual Total of Disengagements', 'DEC-1', 'JAN', 'FEB', 'MAR', 'APR',\n",
    "       'MAY', 'JUN', 'JULY', 'AUG', 'SEP', 'OCT', 'NOV', 'Mileage Total',\n",
    "       ]\n",
    "\n",
    "for col in cast_as_float:\n",
    "    mileage_df[col] = mileage_df[col].apply(lambda x: x.replace(',', '').replace(' ', '') if isinstance(x, str) else x)\n",
    "    mileage_df[col] = mileage_df[col].astype(float)\n",
    "\n",
    "# Assuming df is your DataFrame and 'Column_Name' is the name of the column you want to convert to represent years\n",
    "mileage_df['Year'] = pd.to_datetime(mileage_df['Year']).dt.year\n",
    "mileage_df[\"Manufacturer\"] = mileage_df[\"Manufacturer\"].astype(str)\n",
    "\n",
    "\n",
    "print(f'After: {mileage_df.dtypes}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d412e1",
   "metadata": {},
   "source": [
    "QA: Ensure sum of monthly miles still equals Annual totals after column shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5befa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QA the monthly vs sum values\n",
    "# Calculate the sum of values in the month columns for each row\n",
    "month_sums = mileage_df.iloc[:, 4:-2].sum(axis=1)  \n",
    "\n",
    "# Calculate the absolute difference between the sum of month columns and the \"Mileage Total\" column\n",
    "absolute_difference = abs(month_sums - mileage_df['Mileage Total'])\n",
    "\n",
    "# Check if the absolute difference is less than or equal to 2.0\n",
    "within_tolerance = absolute_difference <= 2.0\n",
    "fishy = (~within_tolerance).sum()\n",
    "print(\"Number of rows where months do not add up to within 1.0 of annual total:\", fishy)\n",
    "\n",
    "# Print rows where the absolute difference is not within 2.0\n",
    "# print(mileage_df[~within_tolerance])\n",
    "qa = mileage_df[~within_tolerance]\n",
    "print(f'Rows where MileageTotal is null: {qa[\"Mileage Total\"].isnull().sum()}')\n",
    "qa.head()\n",
    "\n",
    "\n",
    "# count all nulls \n",
    "print(mileage_df.isnull().sum())\n",
    "mileage_df.dropna(subset=['Mileage Total'], inplace=True)\n",
    "# Drops majority of other nulls\n",
    "print(mileage_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad80e1",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dis_df.rename(columns = {\"Manufacturer\" : \"OPERATOR\",\n",
    "                                  \"DISENGAGEMENT\\nLOCATION\\n(Interstate, Freeway, Highway, Rural Road, Street, or Parking Facility)\" : \"DISENGAGEMENT LOCATION\", \n",
    "                                  \"DISENGAGEMENT INITIATED BY\\n(AV System, Test Driver, Remote Operator, or Passenger)\" : \"INITIATED BY\",\n",
    "                                  \"DRIVER PRESENT\\n(Yes or No)\" : \"DRIVER PRESENT\",\n",
    "                                  \"VEHICLE IS CAPABLE OF OPERATING WITHOUT A DRIVER\\n(Yes or No)\" : \"NVO CAPABLE\"}, inplace=True)\n",
    "\n",
    "\n",
    "mileage_df.rename(columns = {\"Manufacturer\" : \"OPERATOR\"}, inplace=True)\n",
    "combined_dis_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82967afa",
   "metadata": {},
   "source": [
    "Reduce Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DEDUPLICATOR\n",
    "def polish(df, column):\n",
    "   df[column]=df[column].str.upper() # Capitalize everything\n",
    "   df[column] = df[column].str.replace(\"[.,]\", \"\", regex=True) # Remove periods and commas \n",
    "   df[column] = df[column].str.replace(r'\\b(LLC|INC)\\b', '', regex=True)  # Remove \"LLC\" and \"INC\"\n",
    "   df[column]=df[column].str.rstrip() # Remove trailing whitespace\n",
    "\n",
    "   return df \n",
    "\n",
    "print('---------DISENGAGEMENTS:----------')\n",
    "# Print statements are for verification and team review. Might leave them to show class \"This is the mess of data we had to clean up\" - discuss\n",
    "print(f'Locations: {combined_dis_df[\"DISENGAGEMENT LOCATION\"].nunique()} - {sorted(combined_dis_df[\"DISENGAGEMENT LOCATION\"].unique())}')\n",
    "print(f'Operators: {combined_dis_df[\"OPERATOR\"].nunique()} - {sorted(combined_dis_df[\"OPERATOR\"].unique())}')\n",
    "print()\n",
    "\n",
    "dis_columns_to_clean = [\"DISENGAGEMENT LOCATION\", \"OPERATOR\", \"INITIATED BY\"]\n",
    "\n",
    "# Deuplicate Disengagements dataframe\n",
    "for i in dis_columns_to_clean:\n",
    "   combined_dis_df = polish(combined_dis_df, i)\n",
    "# Set VIN as Index\n",
    "#combined_dis_df.set_index(\"VIN NUMBER\", inplace=True)\n",
    "\n",
    "\n",
    "print(f'Cleaned locations: {combined_dis_df[\"DISENGAGEMENT LOCATION\"].nunique()} - {sorted(combined_dis_df[\"DISENGAGEMENT LOCATION\"].unique())}')\n",
    "print(f'Cleaned operators: {combined_dis_df[\"OPERATOR\"].nunique()} - {sorted(combined_dis_df[\"OPERATOR\"].unique())}')\n",
    "print()\n",
    "\n",
    "# Deduplicate Mileage dataframe\n",
    "print('------MILEAGE:--------')\n",
    "print(\"Original number of operators: \", mileage_df[\"OPERATOR\"].nunique())\n",
    "\n",
    "miles_columns_to_clean = [\"OPERATOR\"]\n",
    "\n",
    "# Deuplicate Operators\n",
    "for i in miles_columns_to_clean:\n",
    "   mileage_df = polish(mileage_df, i)\n",
    "\n",
    "# Mop up the last operators name alignment\n",
    "operator_name_dic = {\"APOLLO AUTONOMOUS DRIVING USA\" : \"APOLLO\",\n",
    "                     \"AUTOX TECHNOLOGIES\" : \"AUTOX\",\n",
    "                     'MERCEDES-BENZ RESEARCH & DEVELOPMENT NORTH AMERICA' : 'MERCEDES-BENZ',\n",
    "                     'NISSAN NORTH AMERICA  DBA ALLIANCE INNOVATION LAB' : 'NISSAN',\n",
    "                     'NVIDIA CORPORATION' : 'NVIDIA'\n",
    "}\n",
    "\n",
    "mileage_df[\"OPERATOR\"] = mileage_df[\"OPERATOR\"].replace(operator_name_dic)\n",
    "\n",
    "print(\"Actual number of unique operators: \", mileage_df[\"OPERATOR\"].nunique())\n",
    "\n",
    "operators = sorted(mileage_df[\"OPERATOR\"].unique())\n",
    "for value in operators:\n",
    "    pprint(value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f725d",
   "metadata": {},
   "source": [
    "### GRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c90d8",
   "metadata": {},
   "source": [
    "### Big Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF without zero mile cars\n",
    "nonzero_mileage = mileage_df[(mileage_df[\"Mileage Total\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175270c1-e22f-46f8-85d3-ca955f111c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Histogram: miles driven / VIN ######\n",
    "fig = px.histogram(nonzero_mileage,\n",
    "             x='Mileage Total', color=\"OPERATOR\", title=\"Autonomous Mileage by Vehicle (2021-2023)\", nbins=50)\n",
    "fig.update_layout(xaxis_title='Vehicle Mileage', yaxis_title='Number of Vehicles', height=600, width=1000)\n",
    "fig.show()\n",
    "\n",
    "#### Histogram: miles driven / Operator ######\n",
    "manufacturer_miles_sum = nonzero_mileage.groupby('OPERATOR')['Mileage Total'].sum().reset_index()\n",
    "\n",
    "fig = px.histogram(manufacturer_miles_sum, x='Mileage Total', title='Total Miles Driven Per Operator (2021-2023)', hover_name=\"OPERATOR\",\n",
    "                   labels={'Mileage Total': 'Total Miles Driven'},  nbins=50, color=\"OPERATOR\",\n",
    "                    color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "fig.update_layout(yaxis_title='Operators', height=600, width=1000)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a64a0",
   "metadata": {},
   "source": [
    "#### Total Miles driven per year \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d729849",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ba913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the sum of Mileage Total by Year and OPERATOR\n",
    "agg_df = mileage_df.groupby(['OPERATOR', 'Year'])['Mileage Total'].sum().reset_index()\n",
    "    \n",
    "# Filter to include only data for the top 10 operators\\n\",\n",
    "top_7_operators = mileage_df.groupby('OPERATOR')['Mileage Total'].sum().nlargest(7).index\n",
    "top_miles = agg_df[agg_df['OPERATOR'].isin(top_7_operators)]\n",
    "manufacturer_order = agg_df.groupby('OPERATOR')['Mileage Total'].sum().sort_values(ascending=False).index\n",
    "line_go_up = mileage_df.groupby(['Year'])['Mileage Total'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots to allow for a shared x-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "\n",
    "# Define colors using Viridis color scale\n",
    "colors = px.colors.sequential.Viridis[:len(top_miles['OPERATOR'].unique())]\n",
    "\n",
    "# Add bar chart for each operator\n",
    "operators = top_miles['OPERATOR'].unique()\n",
    "for i, operator in enumerate(operators):\n",
    "    df_filtered = top_miles[top_miles['OPERATOR'] == operator]\n",
    "    fig.add_trace(go.Bar(x=df_filtered['Year'], y=df_filtered['Mileage Total'], name=f\"{operator}\", text=operator,\n",
    "                         marker_color=colors[i]), secondary_y=False)\n",
    "\n",
    "# Add line graph\n",
    "fig.add_trace(go.Scatter(x=line_go_up['Year'], y=line_go_up['Mileage Total'], mode='lines+markers', name='Industry Yearly Total',\n",
    "                         marker_color='black'), secondary_y=False)\n",
    "\n",
    "# Update axes and layout\n",
    "fig.update_layout(title_text=\"Mileage by Year and Operator\", height=600, width=1200)\n",
    "fig.update_xaxes(title_text=\"Year\", tickmode='linear', dtick=1)\n",
    "fig.update_yaxes(title_text=\"Mileage Total\", secondary_y=False, showgrid=True)\n",
    "\n",
    "fig.write_image(\"Images/annual_mileage.jpg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052dc66",
   "metadata": {},
   "source": [
    "### Disengagements across industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bddba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c93ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dis_df[\"OPERATOR\"] = combined_dis_df[\"OPERATOR\"].replace(operator_name_dic)\n",
    "\n",
    "\n",
    "\n",
    "combined_dis_df[\"Year\"] = combined_dis_df[\"DATE\"].dt.year\n",
    "where_dis = combined_dis_df.groupby([\"DISENGAGEMENT LOCATION\"]).size().reset_index(name='Count')\n",
    "\n",
    "fig = px.bar(where_dis.sort_values(\"Count\", ascending=False),\n",
    "             x=\"DISENGAGEMENT LOCATION\",\n",
    "             y=\"Count\",\n",
    "             #color=\"OPERATOR\",\n",
    "             color_discrete_sequence= px.colors.sequential.Viridis)\n",
    "fig.update_layout(height=600, width=700, title=\"Location of Disengagements\")\n",
    "fig.write_image(\"Images/disengagement_locs.jpg\")\n",
    "fig.show()\n",
    "\n",
    "who_dis = combined_dis_df.groupby([\"INITIATED BY\"]).size().reset_index(name='Count')\n",
    "fig = px.bar(who_dis.sort_values(\"Count\", ascending=False),\n",
    "             x=\"INITIATED BY\",\n",
    "             y=\"Count\",\n",
    "             #color=\"OPERATOR\",\n",
    "             color_discrete_sequence= px.colors.sequential.Viridis)\n",
    "fig.update_layout(height=600, width=700, title=\"Disengagement Triggered By:\")\n",
    "fig.write_image(\"Images/disengagement_why.jpg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02df8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DISENGAGEMENTS PER THOUSAND MILES DRIVEN\n",
    "\n",
    "# Group by manufacturer - get VIN count, total disengagments and total miles\n",
    "dptm = nonzero_mileage.groupby(['OPERATOR', 'Year']).agg({'Mileage Total': 'sum',\n",
    "                                                              'Annual Total of Disengagements': 'sum',\n",
    "                                                              'VIN NUMBER': 'nunique'}).reset_index()\n",
    "# Calculate DPTM\n",
    "dptm[\"Disengagements/Thousand Miles\"] = (dptm['Annual Total of Disengagements'] / (dptm['Mileage Total'] / 1000))\n",
    "\n",
    "# Lowest DPTM Operators\n",
    "smoothest_operators = dptm.groupby('OPERATOR')['Disengagements/Thousand Miles'].sum().nsmallest(10).index\n",
    "# Simple Yearly Aggregate of DPTM per Operator\n",
    "agg_2 = dptm.groupby(['OPERATOR', 'Year'])['Disengagements/Thousand Miles'].sum().reset_index()\n",
    "# agg_2 filtered by smoothest operators (best 10)\n",
    "lowest_disengage_rate = agg_2[agg_2['OPERATOR'].isin(smoothest_operators)]\n",
    "\n",
    "# DPTM df filtered down to 10 best @ DPTM\n",
    "dptm_filtered_10 = dptm[dptm['OPERATOR'].isin(smoothest_operators)]\n",
    "\n",
    "dptm_total = nonzero_mileage.groupby(['OPERATOR']).agg({'Mileage Total': 'sum',\n",
    "                                                              'Annual Total of Disengagements': 'sum'}).reset_index()\n",
    "dptm_total[\"Disengagements/Thousand Miles\"] = (dptm_total['Annual Total of Disengagements'] / (dptm_total['Mileage Total'] / 1000))\n",
    "\n",
    "dptm.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f4e37",
   "metadata": {},
   "source": [
    "### Graphing RATE of dsengagements against total miles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0504ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing each operator each year \n",
    "fig = px.scatter(dptm, x=\"Mileage Total\", y=\"Disengagements/Thousand Miles\", color=\"OPERATOR\",\n",
    "                 color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "fig.update_layout(title='Operator Yearly Disengagements Per Thousand Miles v. Total Mileage - All Operators', height=600, width=1200)\n",
    "fig.write_image(\"Images/disengagements_per_thousand_miles_vs_miles_driven.jpg\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8c09a",
   "metadata": {},
   "source": [
    "Causes of Disengagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud of Disengagement descriptions\n",
    "text = combined_dis_df[\"DESCRIPTION OF FACTS CAUSING DISENGAGEMENT\"].values \n",
    "\n",
    "coloring = np.array(Image.open('Images/av2.jpg'))\n",
    "stop_words = [\"vehicle\", \"/n\", \"Non\", \"road\"] + list(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords = stop_words,  max_font_size=500, random_state=3,mask=coloring).generate(str(text))\n",
    "\n",
    "image_colors = ImageColorGenerator(coloring)\n",
    "\n",
    "plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "wordcloud.to_file(\"Images/disengagements_wc.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0165578b",
   "metadata": {},
   "source": [
    "## COLLSIONS !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import time and place collision data\n",
    "coll_time_place_df = pd.read_csv('data/collisions/dataframes/locations/crash_locations.csv')\n",
    "\n",
    "# Clean it:\n",
    "coll_columns_to_clean = [\"Operator\",\"Business\"]\n",
    "for i in coll_columns_to_clean:\n",
    "   coll_time_place_df = polish(coll_time_place_df, i)\n",
    "\n",
    "unique_operator = coll_time_place_df[\"Operator\"].unique()\n",
    "print(unique_operator)\n",
    "\n",
    "coll_time_place_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506333cb",
   "metadata": {},
   "source": [
    "Collision time of day histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd960c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temprorary column to fix binning issues\n",
    "coll_time_place_df['Hour_of_day'] = pd.to_datetime(coll_time_place_df['Time_of_accident_24hr']).dt.strftime('%H')\n",
    "\n",
    "# Plot a histogram with Plotly Express\n",
    "fig = px.histogram(coll_time_place_df.sort_values('Hour_of_day'), \n",
    "                   x='Hour_of_day',\n",
    "                   title='Autonomy Collisions by Time of Day',\n",
    "                   nbins=24,  # One bin for each hour\n",
    "                   labels={'Hour_of_day': 'Hour of Day', 'count': 'Number of Collisions'},\n",
    "                   color='Business',  # Color by operator\n",
    "                   color_discrete_sequence=px.colors.sequential.Viridis\n",
    "                  )\n",
    "\n",
    "fig.update_layout(xaxis_title='Hour of Day', yaxis_title='Number of Collisions', height=600, width=1200)\n",
    "fig.write_image('Images/collisions_by_hour.jpg')\n",
    "fig.show()\n",
    "\n",
    "#drop temp column\n",
    "coll_time_place_df.drop(columns=([\"Hour_of_day\"]), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f454f1",
   "metadata": {},
   "source": [
    "Collision Day of Year histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebe433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date_of_Accident' to datetime\n",
    "coll_time_place_df['Date_of_Accident'] = pd.to_datetime(coll_time_place_df['Date_of_Accident'])\n",
    "# Get mm-DD pair\n",
    "coll_time_place_df['Month'] = coll_time_place_df['Date_of_Accident'].dt.month\n",
    "coll_time_place_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by month and count the number of collisions\n",
    "collisions_by_month = coll_time_place_df.groupby('Month').size().reset_index(name='Count')\n",
    "\n",
    "# Rename month numbers to month names for better visualization\n",
    "month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',\n",
    "               7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "collisions_by_month['Month'] = collisions_by_month['Month'].map(month_names)\n",
    "\n",
    "# Plot histogram\n",
    "fig = px.bar(collisions_by_month, x='Month', y='Count', \n",
    "             title=\"Autonomous Collisions by Month\", \n",
    "             labels={'Month': 'Month', 'Count': 'Number of Collisions'},\n",
    "             color='Month',  # Color by operator\n",
    "             color_discrete_sequence=[px.colors.sequential.Viridis[1]]*len(collisions_by_month))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title='Month', yaxis_title='Number of Collisions', showlegend=False, height=600, width=900)\n",
    "fig.write_image(\"Images/collisions_by_month.jpg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756b08d",
   "metadata": {},
   "source": [
    "Collisions description wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_description = pd.read_csv('data/collisions/dataframes/descriptions/descriptions.csv')\n",
    "\n",
    "description = collision_description[\"Description\"].values \n",
    "\n",
    "coloring = np.array(Image.open('Images/av2.jpg'))\n",
    "stop_words = [\"/n\"] + list(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords = stop_words,  max_font_size=100, random_state=4,mask=coloring).generate(str(description))\n",
    "\n",
    "image_colors = ImageColorGenerator(coloring)\n",
    "\n",
    "plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322637d",
   "metadata": {},
   "source": [
    "Collisions Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_coord = {'Left Rear 1': [0, 2.5],\n",
    "'Rear Bumper' : [0, 1.5],\n",
    "'Right Rear 1' : [0, 0.5],\n",
    "'Left Rear 2': [1, 3],\n",
    "'Left Rear 3': [1, 2],\n",
    "'Right Rear 2': [1, 1],\n",
    "'Right Rear 3': [1, 0],\n",
    "'Left Rear Passenger 1': [2, 3],\n",
    "'Left Rear Passenger 2': [2, 2],\n",
    "'Right Rear Passenger 1': [2, 1],\n",
    "'Right Rear Passenger 2': [2, 0],\n",
    "'Left Rear Passenger 3': [3, 3],\n",
    "'Left Rear Passenger 4': [3, 2],\n",
    "'Right Rear Passenger 3': [3, 1],\n",
    "'Right Rear Passenger 4': [3, 0],\n",
    "'Front Driver Side 1': [4, 3],\n",
    "'Front Driver Side 2': [4, 2],\n",
    "'Front Passenger Side 1': [4, 1],\n",
    "'Front Passenger Side 2': [4, 0],\n",
    "'Front Driver Side 3': [5, 3],\n",
    "'Front Driver Side 4': [5, 2],\n",
    "'Front Passenger Side 3': [5, 1],\n",
    "'Front Passenger Side 4': [5, 0],\n",
    "'Left Front Corner 1': [6, 3],\n",
    "'Left Front Corner 2': [6, 2],\n",
    "'Right Front Corner 1': [6, 1],\n",
    "'Right Front Corner 2': [6, 0],\n",
    "'Left Front Corner 3' : [7, 2.5],\n",
    "'Front Bumper': [7, 1.5],\n",
    "'Right Front Corner 3': [7, 0.5]}\n",
    "\n",
    "damage_df = pd.read_csv('data/collisions/dataframes/damage_map/damage.csv')\n",
    "\n",
    "damage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22908d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns_to_drop = ['Unknown', 'None', 'minor', 'Moderate', 'major', 'Autonomous Mode', 'Unnamed: 0']\n",
    "\n",
    "# Filter DataFrame to include only rows where \"Autonomous Mode\" is True\n",
    "autonomous_damage_df = damage_df[damage_df['Autonomous Mode'] == 1]\n",
    "\n",
    "autonomous_damage_df = autonomous_damage_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Create an empty heatmap matrix\n",
    "heatmap_data = pd.DataFrame(index=range(8), columns=range(16), data=0)\n",
    "\n",
    "# Iterate over each row\n",
    "for i, row in autonomous_damage_df.iterrows():\n",
    "    # Iterate over each column\n",
    "    for label, coord in label_to_coord.items():\n",
    "        # If damage occurred at this location (True value), increment heatmap value\n",
    "        if row[label]:\n",
    "            y_coord = int(coord[1] * 2)\n",
    "            x_coord = int(coord[0] * 2)\n",
    "            heatmap_data.at[y_coord, x_coord] += 1\n",
    "\n",
    "\n",
    "# Reverse the order of rows to flip the heatmap vertically\n",
    "heatmap_data = heatmap_data.iloc[::-1]\n",
    "\n",
    "# make zero-value tiles transparent\n",
    "mask = heatmap_data == 0\n",
    "\n",
    "plt.figure(figsize=(11, 6)) \n",
    "sns.heatmap(heatmap_data, cmap='inferno', annot=False, fmt='d', cbar=True, mask=mask, alpha=0.8)\n",
    "\n",
    "# Load car image\n",
    "img = plt.imread('Images/top_view.jpg')  \n",
    "\n",
    "# Size background\n",
    "plt.imshow(img, aspect='auto', extent=[0, 16, 0, 8])\n",
    "\n",
    "plt.title('Damage Heatmap - Autonomous Mode Only')\n",
    "plt.savefig('Images/autonomous_damage_heatmap.png') \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee90607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Non autonomous\n",
    "columns_to_drop = ['Unknown', 'None', 'minor', 'Moderate', 'major', 'Autonomous Mode', 'Unnamed: 0']\n",
    "\n",
    "# Filter DataFrame to include only rows where \"Autonomous Mode\" is True\n",
    "conventional_damage_df = damage_df[damage_df['Autonomous Mode'] == 0]\n",
    "\n",
    "conventional_damage_df = conventional_damage_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Create an empty heatmap matrix\n",
    "heatmap_data = pd.DataFrame(index=range(8), columns=range(16), data=0)\n",
    "\n",
    "# Iterate over each row\n",
    "for i, row in conventional_damage_df.iterrows():\n",
    "    # Iterate over each column\n",
    "    for label, coord in label_to_coord.items():\n",
    "        # If damage occurred at this location (True value), increment heatmap value\n",
    "        if row[label]:\n",
    "            y_coord = int(coord[1] * 2)\n",
    "            x_coord = int(coord[0] * 2)\n",
    "            heatmap_data.at[y_coord, x_coord] += 1\n",
    "\n",
    "\n",
    "# Reverse the order of rows to flip the heatmap vertically\n",
    "heatmap_data = heatmap_data.iloc[::-1]\n",
    "\n",
    "mask = heatmap_data == 0\n",
    "\n",
    "plt.figure(figsize=(11, 6))  # Adjust width and height as needed\n",
    "\n",
    "\n",
    "sns.heatmap(heatmap_data, cmap='inferno', annot=False, fmt='d', cbar=True,mask=mask, alpha=0.8)\n",
    "\n",
    "# Load the image\n",
    "img = plt.imread('Images/top_view.jpg')  \n",
    "\n",
    "# Size it\n",
    "plt.imshow(img, aspect='auto', extent=[0, 16, 0, 8])\n",
    "\n",
    "plt.title('Damage Heatmap - Conventional Mode Only')\n",
    "plt.savefig('Images/conventional_damage_heatmap.png') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "autonomous_damage_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5aa03",
   "metadata": {},
   "source": [
    "Check columns for joining below  (collisions and Disengagements (per thousand miles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02000fa0",
   "metadata": {},
   "source": [
    "# Waymo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miles per month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disengagements by year by type\n",
    "# Make FOCUS dataframe\n",
    "focus_company = \"WAYMO\"\n",
    "focus_dis_df = combined_dis_df[combined_dis_df['OPERATOR'] == focus_company]\n",
    "# Year column\n",
    "focus_dis_df['Year'] = focus_dis_df['DATE'].dt.year\n",
    "\n",
    "causes_dict = {'Disengage for a recklessly behaving road user' : 'Other driver',\n",
    " 'Disengage for unwanted maneuver of the vehicle that was undesirable under the circumstances' : 'Motion Planning',\n",
    " \"Disengage for a perception discrepancy for which a component of the vehicle's perception system failed to detect an object correctly\" : \"Perception\",\n",
    " \"Disengage for a hardware discrepancy for which our vehicle's diagnostics received a message indicating a potential performance issue with a hardware component of the self-driving system or a component of the base vehicle\" : \"Diagnositc: Hardware\",\n",
    " \"Disengage for a software discrepancy for which our vehicle's diagnostics received a message indicating a potential performance issue with a software component\" : \"Diagnositc: Software\",\n",
    " 'Disengage for incorrect behavior prediction of other traffic participants': \"Prediciton\"}\n",
    "\n",
    "focus_dis_df[\"DESCRIPTION OF FACTS CAUSING DISENGAGEMENT\"].replace(causes_dict,inplace=True)\n",
    " \n",
    "grouped_focus = focus_dis_df.groupby(['DESCRIPTION OF FACTS CAUSING DISENGAGEMENT', 'Year']).size().reset_index(name='Count')\n",
    "\n",
    "\n",
    "fig = px.bar(grouped_focus, x='Year', y='Count', color='DESCRIPTION OF FACTS CAUSING DISENGAGEMENT',\n",
    "             title='WAYMO Disengagement Categories',\n",
    "             labels={'DESCRIPTION OF FACTS CAUSING DISENGAGEMENT': 'Description of Disengagement Facts',\n",
    "                     'Count': 'Count of Disengagement Facts'},            \n",
    "             color_discrete_sequence=px.colors.sequential.Viridis,\n",
    "             barmode='group')\n",
    "fig.update_layout(height = 600, width = 1000)\n",
    "fig.write_image(\"Images/Waymo_disengagements.jpg\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "waymo_focus_df = dptm[dptm['OPERATOR']=='WAYMO']\n",
    "\n",
    "coll_time_place_df['Date_of_Accident'] = pd.to_datetime(coll_time_place_df['Date_of_Accident'])\n",
    "\n",
    "coll_time_place_df['Year'] = coll_time_place_df['Date_of_Accident'].dt.year\n",
    "coll_time_place_df.drop(columns=[\"Business\", \"location\",\"city\", \"county\", \"state\", \"zip\", \"Time_of_accident_24hr\", \"Month\", \"Date_of_Accident\"], inplace=True)\n",
    "coll_time_place_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "waymo_coll_df = coll_time_place_df[coll_time_place_df[\"Operator\"]==\"WAYMO\"]\n",
    "waymo_coll_df.head()\n",
    "\n",
    "grouped_waymo_coll_df = waymo_coll_df.groupby(['Year', 'Operator']).size().reset_index(name='collisions')\n",
    "grouped_waymo_coll_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "waymo_focus_df = pd.merge(waymo_focus_df, grouped_waymo_coll_df, on='Year', how='left')\n",
    "waymo_focus_df['Collisions Per Million Miles Driven'] = round((waymo_focus_df['collisions'] / waymo_focus_df['Mileage Total'] / 0.000001),2)\n",
    "waymo_focus_df['Disengagements Per Million Miles Driven'] = round((waymo_focus_df['Disengagements/Thousand Miles'] / 0.001),2)\n",
    "waymo_focus_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e904c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grouped bar chart using Plotly Express\n",
    "fig = px.bar(waymo_focus_df, x='Year', y=['Collisions Per Million Miles Driven', 'Disengagements Per Million Miles Driven'],\n",
    "             title='Collisions and Disengagements per Million Miles by Year',\n",
    "             labels={'value': 'Count', 'variable': 'Metric'},\n",
    "             barmode='group',\n",
    "             color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "\n",
    "fig.update_layout(height = 600, width = 1000)\n",
    "fig.write_image(\"Images/Waymo_disengagements_collisions_rate.jpg\")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d317b",
   "metadata": {},
   "source": [
    "All operators, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad4da0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_time_place_df['Date_of_Accident'] = pd.to_datetime(coll_time_place_df['Date_of_Accident'])\n",
    "\n",
    "coll_time_place_df['Year'] = coll_time_place_df['Date_of_Accident'].dt.year\n",
    "grouped_coll_df = coll_time_place_df.groupby(['Operator', 'Year']).size().reset_index(name='collisions')\n",
    "grouped_coll_df.rename(columns={'Operator':'OPERATOR'}, inplace=True)\n",
    "print(grouped_coll_df['Year'].dtypes)\n",
    "grouped_coll_df['Year'] = grouped_coll_df['Year'].astype(int)\n",
    "grouped_coll_df.head()\n",
    "dptm.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_dis_group_df = pd.merge(grouped_coll_df, dptm, on=['OPERATOR','Year'], how='inner')\n",
    "coll_dis_group_df = coll_dis_group_df[coll_dis_group_df['Year'] == 2022]\n",
    "coll_dis_group_df['Collisions/Thousand Miles'] = round((coll_dis_group_df['collisions'] / coll_dis_group_df['Mileage Total'] / 0.001), 4)\n",
    "coll_dis_group_df['Disengagements/Thousand Miles'] = round(coll_dis_group_df['Disengagements/Thousand Miles'], 4)\n",
    "coll_dis_group_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to have a single column for the count values\n",
    "melted_df = coll_dis_group_df.melt(id_vars='OPERATOR', \n",
    "                                    value_vars=['Collisions/Thousand Miles', 'Disengagements/Thousand Miles'],\n",
    "                                    var_name='Metric', value_name='Count per Thousand Miles')\n",
    "\n",
    "# Plot grouped horizontal bar chart using Plotly Express\n",
    "fig = px.bar(melted_df,\n",
    "             y='OPERATOR', \n",
    "             x='Count per Thousand Miles', \n",
    "             color='Metric', \n",
    "             orientation='h',\n",
    "             barmode='group',\n",
    "             title='2022 Collisions and Disengagements per Thousand Miles by Operator',\n",
    "             labels={'OPERATOR': 'Operator', 'Count per Thousand Miles': 'Count per Thousand Miles', \n",
    "                     'Metric': 'Metric'},\n",
    "             color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "\n",
    "\n",
    "fig.update_layout(height = 600, width = 1000)\n",
    "fig.write_image(\"Images/2022_disengagements_collisions_rate.jpg\")\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ed58a",
   "metadata": {},
   "source": [
    "# Zippy and Pokey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbf245",
   "metadata": {},
   "outputs": [],
   "source": [
    "miles_by_vin = mileage_df.groupby(\"VIN NUMBER\")[\"Mileage Total\"].sum().sort_values(ascending=False)\n",
    "zippy = miles_by_vin.idxmax()\n",
    "zippy_mi = miles_by_vin[zippy]\n",
    "pokey = miles_by_vin.idxmin()\n",
    "pokey_mi = miles_by_vin[pokey]\n",
    "\n",
    "\n",
    "print(f'Zippy VIN is {zippy}')\n",
    "print(f'Zippy is a {mileage_df.loc[mileage_df[\"VIN NUMBER\"] == zippy, \"OPERATOR\"].unique()[0]} vehicle, which drove {zippy_mi} miles.')\n",
    "\n",
    "print(f'Pokey VIN is {pokey}')\n",
    "print(f'Pokey is a {mileage_df.loc[mileage_df[\"VIN NUMBER\"] == pokey, \"OPERATOR\"].unique()[0]} vehicle, which drove {pokey_mi} miles.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fec7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of miles over time?\n",
    "# Combined graph - line: miles, columns, disengagements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunburst of mileage by month? \n",
    "# what sotry? weather vehicles can/can't run in\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
