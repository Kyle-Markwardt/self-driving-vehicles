{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7de0c1",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "    - Refine narrative\n",
    "    - Make plots\n",
    "    - Determine presentation form\n",
    "        - Kyle: partial to some kind of web app\n",
    "\n",
    "## Notes\n",
    "\n",
    "- DB- Note on file names.  I slightly edited file names (I think to include a -) so the names  would be sufficiently uniform, for reading into dfs.  Let's ensure this is pushed correctly. \n",
    "- RE: CSV file inputs and date ranges.  I observe there is no 2022 autonomous vehicle disengagement report- driverless on the DMV website\n",
    "- Similarily, there is something going on in the driverless mileage reports.\n",
    "- The 2020-21-Autonomous-Mileage-Reports-CSV-driverless covers Jan 2020 - Nov 2021\n",
    "- The 2021-22-Autonomous-Mileage-Reports-CSV-driverless covers Jan 2021 - Nov 2022, but only has 3 lines, for WERIDE CORP,\n",
    "    - Which doesn't appear in the 2020-21 entry.  This is probably due to a delayed filing on their part, and staff did the ez thing.\n",
    "- The 2022 Report starts in Dec 2021 - Nov 2022, and doesn't include WERIDE info (either by name or permit #)\n",
    "- The 2023 Report covers Dec 2022- Nov 2023, and includes WERIDE, so there is no overlaping info.\n",
    "\n",
    "- Re: The mileage reports.  I'm loading them in so the yeoman's work is done.  I don't want to botch joining them.\n",
    "   - Some form of groupby + set_index, as per discord, might be the trick here. \n",
    "   - Alternatively, we can combine the permit # + VIN into a new single column, and this will enable some straightforward y/y granular tracking via joined dfs (m/m from Jan 2020 - Nov 2023)\n",
    "- Finally, we should be on the lookout for permit #s that have company name changes, like the company got bought or something\n",
    "\n",
    "## Narrative, high level, keep refining into story:\n",
    "1. Overall trends, total miles, leaders in the space, etc.\n",
    "2. Cruze story because it's interesting (backup: Waymo)\n",
    "3. Follow 'zippy' the car (longest hauler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af4c23",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff662bd6-1e47-43a8-924f-3f1a7c45d0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy\n",
    "import plotly.express as px\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b09241",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb78dc-84c3-4932-962c-ae8f7db5c475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Lists\n",
    "## Years common across data\n",
    "years = [\"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "years = sorted(list(years))\n",
    "\n",
    "months = [\"DEC-1\", \"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JULY\", \"AUG\", \"SEP\", \"OCT\", \"NOV\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d2e0f",
   "metadata": {},
   "source": [
    "### Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9017a-6e18-47f0-960f-9a8f7b73a72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Cast DATE column as datetype for disengagements\n",
    "\n",
    "## Read in mileage data\n",
    "mile_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='latin-1')\n",
    "    annual_mileage[\"Year\"] = year\n",
    "    annual_mileage.rename(columns={'ANNUAL TOTAL': 'Mileage Total'}, inplace=True)\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_mileage.columns.values[i] = month\n",
    "    mile_dfs.append(annual_mileage)\n",
    "    # INFO: each annual report has 22 cols\n",
    "\n",
    "mileage_df = pd.concat(mile_dfs, ignore_index=True)\n",
    "# mileage_df.set_index('VIN NUMBER', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548203a",
   "metadata": {},
   "source": [
    "First Time Filers - Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb7046-df7d-49fa-b0c9-4c4db90f9c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mile_first_time_filer_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-first-time-filers.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-first-time-filers.csv\", encoding='latin-1')\n",
    "    mile_first_time_filer_dfs.append(annual_disengagements)\n",
    "    \n",
    "# Not combining due to join issue raised at top of document\n",
    "#first_time_mileage_df = pd.concat(mile_first_time_filer, ignore_index=True)\n",
    "\n",
    "#print(mile_first_time_filer_dfs[0].head())\n",
    "print(\"# of objects in mile_driverless_dfs:  \" + str(len(mile_first_time_filer_dfs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21ac82",
   "metadata": {},
   "source": [
    "Driverless Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c52ee2-eab0-4c3d-ad82-9d282275f540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DB - Using the same process I used above, for Autonomous-Mileage-Reports-CSV-driverless.csv & Autonomous-Mileage-Reports-CSV-first-time-filers.csv\n",
    "mile_driverless_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    annual_disengagements[\"Year\"] = year\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_disengagements.columns.values[i] = month\n",
    "    mile_driverless_dfs.append(annual_disengagements)\n",
    "\n",
    "for year in years:    \n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "        # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "        # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    annual_disengagements[\"Year\"] = year\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_disengagements.columns.values[i] = month\n",
    "    mile_driverless_dfs.append(annual_disengagements)\n",
    "\n",
    "driverless_mileage_df = pd.concat(mile_driverless_dfs, ignore_index=True)\n",
    "# TODO: deal with stupid double year file.\n",
    "\n",
    "#print(mile_driverless_dfs[0].head())\n",
    "print(\"# of objects in mile_driverless_dfs:  \" + str(len(mile_driverless_dfs)))\n",
    "driverless_mileage_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7ea68",
   "metadata": {},
   "source": [
    "Combined Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Duplicate and modify code from combined disengagements here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89e2e7",
   "metadata": {},
   "source": [
    "### Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf860b08-a42c-4174-bc47-a0af44cc4340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Read in data\n",
    "## Read in disengagements data\n",
    "dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='latin-1')\n",
    "    dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "disengagement_df = pd.concat(dis_dfs, ignore_index=True)\n",
    "\n",
    "#DB.  The unnamed column 10 only appears in the 2021 report, and the 71 entries are all for IMAGRY INC.,\n",
    "# Reading \"Perception\" or \"Planning\"\n",
    "# Dropped Column\n",
    "disengagement_df = disengagement_df.drop('Unnamed: 9', axis=1)\n",
    "#Apx 8k  empty rows.  Droped all rows with any nulls.  \n",
    "disengagement_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8da44d",
   "metadata": {},
   "source": [
    "First Time Filers - Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369e28f-3b82-4c99-aa33-acecabe5c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding in 1st time filer Disengagements.  Utilizing Kyle's code from above\n",
    "first_time_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='latin-1')\n",
    "    first_time_dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "first_df = pd.concat(first_time_dis_dfs, ignore_index=True)\n",
    "#Some 200ish null rows imported. Dropped any row with any missing data\n",
    "first_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45e32e",
   "metadata": {},
   "source": [
    "Driverless Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccbe32-7977-4e1b-9395-91ed1b109269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Driverless reports.  2022 is missing.  There are only 2 files here.  I've combined the above 2x for loops to snag them both, \n",
    "# since they have different naming conventions\n",
    "driverless_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "for year in years:    \n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "        # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "        # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "autonomous_dis_df = pd.concat(driverless_dis_dfs, ignore_index=True)\n",
    "# Dropping some 2000+ null rows.\n",
    "autonomous_dis_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748786cc",
   "metadata": {},
   "source": [
    "Combined Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf3fc9-c6ef-4a7d-8521-ee5066cf226b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3x active DFs for the disengagement info are\n",
    "# disengagement_df\n",
    "# first_df\n",
    "# autonomous_dis_df\n",
    "# List of these objects to for loop the DATE cleanup.  \n",
    "# IF we wanted to acccess the report source from the combined df, we could add a column to each, with the report source\n",
    "\n",
    "# Initially had trouble by converting the dates to_datetime and then trying to drop the hour/min/sec.\n",
    "# Resolved by first converting DATE to str, dropping everything after \" \" (since all times were separated from date by a space)\n",
    "# And then subsequently converting the column to_datetime\n",
    "\n",
    "# This works, but can't be re-run unless above code blocks that create the dfs are also re-run (I think).  \n",
    "# Used print(i['DATE'].value_counts()) to confirm this came out correctly.  \n",
    "\n",
    "disengagement_dfs_list = [disengagement_df, first_df, autonomous_dis_df]\n",
    "\n",
    "for i in disengagement_dfs_list:\n",
    "    i['DATE'] = i['DATE'].astype(str)\n",
    "    i[\"DATE\"] = i[\"DATE\"].str.split(\" \", expand=True)[0]\n",
    "    i['DATE'] = pd.to_datetime(i['DATE'], errors='raise', dayfirst=True, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279e6c6-8311-416c-9da4-1f00ffe034fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for i in disengagement_dfs_list:\n",
    "    #print(i['Permit Number'].value_counts())\n",
    "    print(i.shape)\n",
    "'''\n",
    "\n",
    "# Operator-in-Vehicle = AVT Permit prefix\n",
    "# NVO = AVDT Permit Prefix.\n",
    "# I'm fairly certain splitting these into distinct columns for purposes of multi-indexed rows or columns is straightforward, \n",
    "# So am moving forward with data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c862d-6ec4-4539-885c-530250ea8b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3x disengagement df's combined together into one, single column for all permit info\n",
    "combined_dis_df = pd.concat(disengagement_dfs_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481e0a0",
   "metadata": {},
   "source": [
    "# Data Cleaning and QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f17631",
   "metadata": {},
   "source": [
    "Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are \"Unnamed\" colums? Probably useless \"reserved\"\n",
    "# This and below are from kyle, and deal with the initial mileage_df\n",
    "unnamed_cols = ['Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21']\n",
    "for check in unnamed_cols:\n",
    "    non_null_count = mileage_df[check].notna().sum()\n",
    "    print(f'Number of non values in {check}: {non_null_count}')\n",
    "\n",
    "# Empty. Drop 'em\n",
    "mileage_df = mileage_df.drop(columns=unnamed_cols)\n",
    "mileage_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e09a3",
   "metadata": {},
   "source": [
    "Set Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcaf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mileage\n",
    "print(f'Before: {mileage_df.dtypes}')\n",
    "cast_as_float = [\n",
    "       'Annual Total of Disengagements', 'DEC-1', 'JAN', 'FEB', 'MAR', 'APR',\n",
    "       'MAY', 'JUN', 'JULY', 'AUG', 'SEP', 'OCT', 'NOV', 'Mileage Total',\n",
    "       ]\n",
    "\n",
    "for col in cast_as_float:\n",
    "    mileage_df[col] = mileage_df[col].apply(lambda x: x.replace(',', '').replace(' ', '') if isinstance(x, str) else x)\n",
    "    mileage_df[col] = mileage_df[col].astype(float)\n",
    "\n",
    "# Assuming df is your DataFrame and 'Column_Name' is the name of the column you want to convert to represent years\n",
    "mileage_df['Year'] = pd.to_datetime(mileage_df['Year']).dt.year\n",
    "mileage_df[\"Manufacturer\"] = mileage_df[\"Manufacturer\"].astype(str)\n",
    "\n",
    "\n",
    "print(f'After: {mileage_df.dtypes}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d412e1",
   "metadata": {},
   "source": [
    "QA: Ensure sum of monthly miles still equals Annual totals after column shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5befa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QA the monthly vs sum values\n",
    "# Calculate the sum of values in the month columns for each row\n",
    "month_sums = mileage_df.iloc[:, 4:-2].sum(axis=1)  \n",
    "\n",
    "# Calculate the absolute difference between the sum of month columns and the \"Mileage Total\" column\n",
    "absolute_difference = abs(month_sums - mileage_df['Mileage Total'])\n",
    "\n",
    "# Check if the absolute difference is less than or equal to 2.0\n",
    "within_tolerance = absolute_difference <= 2.0\n",
    "fishy = (~within_tolerance).sum()\n",
    "print(\"Number of rows where months do not add up to within 1.0 of annual total:\", fishy)\n",
    "\n",
    "# Print rows where the absolute difference is not within 2.0\n",
    "# print(mileage_df[~within_tolerance])\n",
    "qa = mileage_df[~within_tolerance]\n",
    "print(f'Rows where MileageTotal is null: {qa[\"Mileage Total\"].isnull().sum()}')\n",
    "qa.head()\n",
    "\n",
    "\n",
    "# count all nulls \n",
    "print(mileage_df.isnull().sum())\n",
    "mileage_df.dropna(subset=['Mileage Total'], inplace=True)\n",
    "# Drops majority of other nulls\n",
    "print(mileage_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad80e1",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dis_df.rename(columns = {\"Manufacturer\" : \"OPERATOR\",\n",
    "                                  \"DISENGAGEMENT\\nLOCATION\\n(Interstate, Freeway, Highway, Rural Road, Street, or Parking Facility)\" : \"DISENGAGEMENT LOCATION\", \n",
    "                                  \"DISENGAGEMENT INITIATED BY\\n(AV System, Test Driver, Remote Operator, or Passenger)\" : \"INITIATED BY\",\n",
    "                                  \"DRIVER PRESENT\\n(Yes or No)\" : \"DRIVER PRESENT\",\n",
    "                                  \"VEHICLE IS CAPABLE OF OPERATING WITHOUT A DRIVER\\n(Yes or No)\" : \"NVO CAPABLE\"}, inplace=True)\n",
    "\n",
    "\n",
    "mileage_df.rename(columns = {\"Manufacturer\" : \"OPERATOR\"}, inplace=True)\n",
    "combined_dis_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82967afa",
   "metadata": {},
   "source": [
    "Reduce Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DEDUPLICATOR\n",
    "def polish(df, column):\n",
    "   df[column]=df[column].str.upper() # Capitalize everything\n",
    "   df[column] = df[column].str.replace(\"[.,]\", \"\", regex=True) # Remove periods and commas \n",
    "   df[column] = df[column].str.replace(r'\\b(LLC|INC)\\b', '', regex=True)  # Remove \"LLC\" and \"INC\"\n",
    "   df[column]=df[column].str.rstrip() # Remove trailing whitespace\n",
    "\n",
    "   return df \n",
    "\n",
    "# Print statements are for verification and team review. Might leave them to show class \"This is the mess of data we had to clean up\" - discuss\n",
    "print(f'Locations: {combined_dis_df[\"DISENGAGEMENT LOCATION\"].nunique()} - {sorted(combined_dis_df[\"DISENGAGEMENT LOCATION\"].unique())}')\n",
    "print(f'Operators: {combined_dis_df[\"OPERATOR\"].nunique()} - {sorted(combined_dis_df[\"OPERATOR\"].unique())}')\n",
    "print()\n",
    "\n",
    "dis_columns_to_clean = [\"DISENGAGEMENT LOCATION\", \"OPERATOR\"]\n",
    "\n",
    "# Deuplicate Disengagements\n",
    "for i in dis_columns_to_clean:\n",
    "   combined_dis_df = polish(combined_dis_df, i)\n",
    "# Set VIN as Index\n",
    "#combined_dis_df.set_index(\"VIN NUMBER\", inplace=True)\n",
    "\n",
    "\n",
    "print(f'Cleaned locations: {combined_dis_df[\"DISENGAGEMENT LOCATION\"].nunique()} - {sorted(combined_dis_df[\"DISENGAGEMENT LOCATION\"].unique())}')\n",
    "print(f'Cleaned operators: {combined_dis_df[\"OPERATOR\"].nunique()} - {sorted(combined_dis_df[\"OPERATOR\"].unique())}')\n",
    "print()\n",
    "\n",
    "# Deduplicate Mileage\n",
    "print(\"Original number of operators: \", mileage_df[\"OPERATOR\"].nunique())\n",
    "\n",
    "miles_columns_to_clean = [\"OPERATOR\"]\n",
    "\n",
    "# Deuplicate Mileage\n",
    "for i in miles_columns_to_clean:\n",
    "   mileage_df = polish(mileage_df, i)\n",
    "\n",
    "print(\"Actual number of unique operators: \", mileage_df[\"OPERATOR\"].nunique())\n",
    "\n",
    "operators = sorted(mileage_df[\"OPERATOR\"].unique())\n",
    "for value in operators:\n",
    "    print(value)\n",
    "\n",
    "# TODO: Mop up the last operators name alignment\n",
    "# mileage_df[\"Manufacturer\"] = mileage_df[\"Manufacturer\"].str.replace('long_duplicates', 'shorter_version')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33401501",
   "metadata": {},
   "source": [
    "### Find 'Zippy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "aa5c8b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zippy VIN is SADHW2S13M1616427\n",
      "Zippy is a WAYMO vehicle.\n"
     ]
    }
   ],
   "source": [
    "miles_by_vin = mileage_df.groupby(\"VIN NUMBER\")[\"Mileage Total\"].sum().sort_values(ascending=False)\n",
    "miles_by_vin.head()\n",
    "zippy = miles_by_vin.idxmax()\n",
    "print(f'Zippy VIN is {zippy}')\n",
    "\n",
    "print(f'Zippy is a {mileage_df.loc[mileage_df[\"VIN NUMBER\"] == zippy, \"OPERATOR\"].unique()[0]} vehicle.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f725d",
   "metadata": {},
   "source": [
    "### GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_mileage = mileage_df[(mileage_df[\"Mileage Total\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175270c1-e22f-46f8-85d3-ca955f111c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  autonomous miles necessarily.  Need to look at data sources further.\n",
    "\n",
    "# TODO: Drop zeroes? Probably.\n",
    "\n",
    "#### Histogram: miles driven / VIN ######\n",
    "vin = px.histogram(nonzero_mileage,\n",
    "             x='Mileage Total', color=\"Manufacturer\", title=\"Autonomous Mileage by Vehicle (2021-2023)\", nbins=50)\n",
    "vin.update_layout(xaxis_title='Vehicle Mileage', yaxis_title='Number of Vehicles')\n",
    "vin.show()\n",
    "\n",
    "#### Histogram: miles driven / Operator ######\n",
    "manufacturer_miles_sum = nonzero_mileage.groupby('Manufacturer')['Mileage Total'].sum().reset_index()\n",
    "\n",
    "fig = px.histogram(manufacturer_miles_sum, x='Mileage Total', title='Total Miles Driven Per Operator (2021-2023)',\n",
    "                   labels={'Mileage Total': 'Total Miles Driven'},  nbins=100)  # Adjust nbins as needed\n",
    "fig.update_layout(yaxis_title='Operators')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### WANT: Would be absolutley sick if we could start with the VINs histogram and animated into the by Operator graph...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kyle - Word cloud of Disengagement descriptions\n",
    "text = combined_dis_df[\"DESCRIPTION OF FACTS CAUSING DISENGAGEMENT\"].values \n",
    "\n",
    "stop_words = [\"vehicle\", \"/n\", \"Non\", \"road\"] + list(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords = stop_words, background_color=\"white\", colormap=\"CMRmap\").generate(str(text))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a11d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b666339",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Miles driven donut by operator? only a few DOMINATE the space.\n",
    "## No need? Show by above graphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if any manufacturers have multiple permit numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunburst of mileage by month? \n",
    "# what sotry? weather vehicles can/can't run in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scatter of number of VINs and total miles? by manufacturer\n",
    "# Bubble size number of disengagements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec884ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scatter of x=miles driven, y=disengagements, by VIN? color by manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13563e0e-aaf7-46b4-95ba-61b35fb0aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Total Miles driven per year ####\n",
    "# Aggregate the sum of \"Mileage Total\" by \"Year\" and \"Manufacturer\"\n",
    "agg_df = mileage_df.groupby(['Manufacturer', 'Year'])['Mileage Total'].sum().reset_index()\n",
    "\n",
    "# Filter to include only data for the top 10 operators\n",
    "top_10_operators = mileage_df.groupby('Manufacturer')['Mileage Total'].sum().nlargest(10).index\n",
    "top_miles = agg_df[agg_df['Manufacturer'].isin(top_10_operators)]\n",
    "manufacturer_order = agg_df.groupby('Manufacturer')['Mileage Total'].sum().sort_values(ascending=False).index\n",
    "\n",
    "\n",
    "# Create the bar plot\n",
    "fig = px.bar(top_miles, x='Year', y='Mileage Total', color='Manufacturer', text=\"Manufacturer\", title='Annual Autonomous Mileage Totals', category_orders={'Manufacturer': manufacturer_order})\n",
    "fig.update_layout(xaxis_title='Year', yaxis_title='Mileage Total')\n",
    "fig.update_xaxes(tickvals=[2021, 2022, 2023])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e31cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Duplicate of above, but line\n",
    "\n",
    "# Create line plot\n",
    "fig = px.line(top_miles, x='Year', y='Mileage Total', color='Manufacturer', text=\"Manufacturer\", title='Annual Mileage Total by Operator')\n",
    "fig.update_layout(xaxis_title='Year', yaxis_title='Mileage Total')\n",
    "fig.update_xaxes(tickvals=[2021, 2022, 2023])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636f319-51e9-4e44-83ca-a67ed5931dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DISENGAGEMENTS PER THOUSAND MILES DRIVEN\n",
    "# Makes most sense to show by year on a per-company basis. \n",
    "\n",
    "# Group by manufacturer - get VIN count, total disengagments and total miles\n",
    "dptm = nonzero_mileage.groupby(['Manufacturer', 'Year']).agg({'Mileage Total': 'sum',\n",
    "                                                              'Annual Total of Disengagements': 'sum',\n",
    "                                                              'VIN NUMBER': 'nunique'}).reset_index()\n",
    "# Calculate DPTM\n",
    "dptm[\"Disengagements/Thousand Miles\"] = (dptm['Annual Total of Disengagements'] / (dptm['Mileage Total'] / 1000))\n",
    "\n",
    "# Lowest DPTM Operators\n",
    "smoothest_operators = dptm.groupby('Manufacturer')['Disengagements/Thousand Miles'].sum().nsmallest(10).index\n",
    "# Simple Yearly Aggregate of DPTM per Operator\n",
    "agg_2 = dptm.groupby(['Manufacturer', 'Year'])['Disengagements/Thousand Miles'].sum().reset_index()\n",
    "# agg_2 filtered by smoothest operators (best 10)\n",
    "lowest_disengage_rate = agg_2[agg_2['Manufacturer'].isin(smoothest_operators)]\n",
    "\n",
    "# DPTM df filtered down to 10 best @ DPTM\n",
    "dptm_filtered_10 = dptm[dptm['Manufacturer'].isin(smoothest_operators)]\n",
    "\n",
    "dptm_total = nonzero_mileage.groupby(['Manufacturer']).agg({'Mileage Total': 'sum',\n",
    "                                                              'Annual Total of Disengagements': 'sum'}).reset_index()\n",
    "dptm_total[\"Disengagements/Thousand Miles\"] = (dptm_total['Annual Total of Disengagements'] / (dptm_total['Mileage Total'] / 1000))\n",
    "\n",
    "dptm_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6445dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do the correlation thing on DPTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ecf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graphing DPTM\n",
    "# Mehhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh tells no story, would be a lot cooler with more years of data\n",
    "fig = px.scatter(dptm, x=\"Mileage Total\", y=\"Annual Total of Disengagements\", \n",
    "                 size=\"VIN NUMBER\", color=\"Manufacturer\",\n",
    "                 animation_frame=\"Year\", animation_group=\"Manufacturer\",\n",
    "                 range_x=[0, dptm[\"Mileage Total\"].max() * 1.1],  # Adjust range for x-axis\n",
    "                 range_y=[0, dptm[\"Annual Total of Disengagements\"].max() * 1.1],  # Adjust range for y-axis\n",
    "                 labels={\"Mileage Total\": \"Annual Mileage\", \"Annual Total of Disengagements\": \"Annual Total of Disengagements\", \"VIN NUMBER\": \"Number of Vehicles\", \"Manufacturer\": \"Manufacturer\", \"Year\": \"Year\"}\n",
    "                )\n",
    "fig.update_layout(title='Total Disengagments vs Total Mileage [Bubble size = No. of Vehicles]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0504ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graphing RATE of dsengagements against total miles\n",
    "fig = px.scatter(dptm, x=\"Mileage Total\", y=\"Disengagements/Thousand Miles\", color=\"Manufacturer\")\n",
    "fig.update_layout(title='Average Annual Disengagements Per Thousand Miles v. Total Mileage - All Opertors')\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(dptm_total, x=\"Mileage Total\", y=\"Disengagements/Thousand Miles\", color=\"Manufacturer\")\n",
    "fig.update_layout(title='Average Disengagements Per Thousand Miles v. Total Mileage - All Opertors (2021-2023)')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca512f5-8fa9-42f5-a2e2-1618433530ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: mileage_df.shape = (4360, 46)\n",
    "print(mileage_df.columns)\n",
    "mileage_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ff0c4-56c1-407b-8dd4-75b087e8b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: disengagement_df.shape = (23579, 10)\n",
    "print(disengagement_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ea08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
