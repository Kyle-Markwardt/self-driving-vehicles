{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7de0c1",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "    - Refine narrative\n",
    "    - Make plots\n",
    "    - Determine presentation form\n",
    "        - Kyle: partial to some kind of web app\n",
    "\n",
    "## Notes\n",
    "\n",
    "- DB- Note on file names.  I slightly edited file names (I think to include a -) so the names  would be sufficiently uniform, for reading into dfs.  Let's ensure this is pushed correctly. \n",
    "- RE: CSV file inputs and date ranges.  I observe there is no 2022 autonomous vehicle disengagement report- driverless on the DMV website\n",
    "- Similarily, there is something going on in the driverless mileage reports.\n",
    "- The 2020-21-Autonomous-Mileage-Reports-CSV-driverless covers Jan 2020 - Nov 2021\n",
    "- The 2021-22-Autonomous-Mileage-Reports-CSV-driverless covers Jan 2021 - Nov 2022, but only has 3 lines, for WERIDE CORP,\n",
    "    - Which doesn't appear in the 2020-21 entry.  This is probably due to a delayed filing on their part, and staff did the ez thing.\n",
    "- The 2022 Report starts in Dec 2021 - Nov 2022, and doesn't include WERIDE info (either by name or permit #)\n",
    "- The 2023 Report covers Dec 2022- Nov 2023, and includes WERIDE, so there is no overlaping info.\n",
    "\n",
    "- Re: The mileage reports.  I'm loading them in so the yeoman's work is done.  I don't want to botch joining them.\n",
    "   - Some form of groupby + set_index, as per discord, might be the trick here. \n",
    "   - Alternatively, we can combine the permit # + VIN into a new single column, and this will enable some straightforward y/y granular tracking via joined dfs (m/m from Jan 2020 - Nov 2023)\n",
    "- Finally, we should be on the lookout for permit #s that have company name changes, like the company got bought or something\n",
    "\n",
    "## Narrative, high level, keep refining into story:\n",
    "1. Overall trends, total miles, leaders in the space, etc.\n",
    "2. Cruze story because it's interesting (backup: Waymo)\n",
    "3. Follow 'zippy' the car (longest hauler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af4c23",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ff662bd6-1e47-43a8-924f-3f1a7c45d0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy\n",
    "import plotly.express as px\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b09241",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb78dc-84c3-4932-962c-ae8f7db5c475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Lists\n",
    "## Years common across data\n",
    "years = [\"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "years = sorted(list(years))\n",
    "\n",
    "months = [\"DEC-1\", \"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JULY\", \"AUG\", \"SEP\", \"OCT\", \"NOV\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d2e0f",
   "metadata": {},
   "source": [
    "### Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9017a-6e18-47f0-960f-9a8f7b73a72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Cast DATE column as datetype for disengagements\n",
    "\n",
    "## Read in mileage data\n",
    "mile_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_mileage = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV.csv\", encoding='latin-1')\n",
    "    annual_mileage[\"Year\"] = year\n",
    "    annual_mileage.rename(columns={'ANNUAL TOTAL': 'Mileage Total'}, inplace=True)\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_mileage.columns.values[i] = month\n",
    "    mile_dfs.append(annual_mileage)\n",
    "    # INFO: each annual report has 22 cols\n",
    "\n",
    "mileage_df = pd.concat(mile_dfs, ignore_index=True)\n",
    "# mileage_df.set_index('VIN NUMBER', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548203a",
   "metadata": {},
   "source": [
    "First Time Filers - Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb7046-df7d-49fa-b0c9-4c4db90f9c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mile_first_time_filer_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-first-time-filers.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-first-time-filers.csv\", encoding='latin-1')\n",
    "    mile_first_time_filer_dfs.append(annual_disengagements)\n",
    "    \n",
    "# Not combining due to join issue raised at top of document\n",
    "#first_time_mileage_df = pd.concat(mile_first_time_filer, ignore_index=True)\n",
    "\n",
    "#print(mile_first_time_filer_dfs[0].head())\n",
    "print(\"# of objects in mile_driverless_dfs:  \" + str(len(mile_first_time_filer_dfs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21ac82",
   "metadata": {},
   "source": [
    "Driverless Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c52ee2-eab0-4c3d-ad82-9d282275f540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DB - Using the same process I used above, for Autonomous-Mileage-Reports-CSV-driverless.csv & Autonomous-Mileage-Reports-CSV-first-time-filers.csv\n",
    "mile_driverless_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-{str(int(year[3]) + 21)}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    annual_disengagements[\"Year\"] = year\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_disengagements.columns.values[i] = month\n",
    "    mile_driverless_dfs.append(annual_disengagements)\n",
    "\n",
    "for year in years:    \n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "        # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "        # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Mileage/{year}-Autonomous-Mileage-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    annual_disengagements[\"Year\"] = year\n",
    "    for i, month in enumerate(months, start=4):\n",
    "        annual_disengagements.columns.values[i] = month\n",
    "    mile_driverless_dfs.append(annual_disengagements)\n",
    "\n",
    "driverless_mileage_df = pd.concat(mile_driverless_dfs, ignore_index=True)\n",
    "# TODO: deal with stupid double year file.\n",
    "\n",
    "#print(mile_driverless_dfs[0].head())\n",
    "print(\"# of objects in mile_driverless_dfs:  \" + str(len(mile_driverless_dfs)))\n",
    "driverless_mileage_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7ea68",
   "metadata": {},
   "source": [
    "Combined Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Duplicate and modify code from combined disengagements here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89e2e7",
   "metadata": {},
   "source": [
    "### Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf860b08-a42c-4174-bc47-a0af44cc4340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for year 2020 not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "### Read in data\n",
    "## Read in disengagements data\n",
    "dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='utf-8')\n",
    "    # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV.csv\", encoding='latin-1')\n",
    "    dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "disengagement_df = pd.concat(dis_dfs, ignore_index=True)\n",
    "\n",
    "#DB.  The unnamed column 10 only appears in the 2021 report, and the 71 entries are all for IMAGRY INC.,\n",
    "# Reading \"Perception\" or \"Planning\"\n",
    "# Dropped Column\n",
    "disengagement_df = disengagement_df.drop('Unnamed: 9', axis=1)\n",
    "#Apx 8k  empty rows.  Droped all rows with any nulls.  \n",
    "disengagement_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8da44d",
   "metadata": {},
   "source": [
    "First Time Filers - Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c369e28f-3b82-4c99-aa33-acecabe5c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for year 2023-24 not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Adding in 1st time filer Disengagements.  Utilizing Kyle's code from above\n",
    "first_time_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-first-time-filers.csv\", encoding='latin-1')\n",
    "    first_time_dis_dfs.append(annual_disengagements)\n",
    "    \n",
    "first_df = pd.concat(first_time_dis_dfs, ignore_index=True)\n",
    "#Some 200ish null rows imported. Dropped any row with any missing data\n",
    "first_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45e32e",
   "metadata": {},
   "source": [
    "Driverless Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "13ccbe32-7977-4e1b-9395-91ed1b109269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for year 2021-22 not found. Skipping...\n",
      "File for year 2022-23 not found. Skipping...\n",
      "File for year 2023-24 not found. Skipping...\n",
      "File for year 2020 not found. Skipping...\n",
      "File for year 2021 not found. Skipping...\n",
      "File for year 2022 not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Driverless reports.  2022 is missing.  There are only 2 files here.  I've combined the above 2x for loops to snag them both, \n",
    "# since they have different naming conventions\n",
    "driverless_dis_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year}-{str(int(year[3]) + 21)} not found. Skipping...\")\n",
    "        continue\n",
    "    # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-{str(int(year[3]) + 21)}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "for year in years:    \n",
    "    try:\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='utf-8')\n",
    "        # Allows the search to be broad\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found. Skipping...\")\n",
    "        continue\n",
    "        # Got some kind of unicode error. This fixed it.\n",
    "    except UnicodeDecodeError:\n",
    "        # If utf-8 decoding fails, try another common encoding\n",
    "        annual_disengagements = pd.read_csv(f\"data/Disengagements/{year}-Autonomous-Vehicle-Disengagement-Reports-CSV-driverless.csv\", encoding='latin-1')\n",
    "    driverless_dis_dfs.append(annual_disengagements)\n",
    "\n",
    "autonomous_dis_df = pd.concat(driverless_dis_dfs, ignore_index=True)\n",
    "# Dropping some 2000+ null rows.\n",
    "autonomous_dis_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748786cc",
   "metadata": {},
   "source": [
    "Combined Disengagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ebdf3fc9-c6ef-4a7d-8521-ee5066cf226b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3x active DFs for the disengagement info are\n",
    "# disengagement_df\n",
    "# first_df\n",
    "# autonomous_dis_df\n",
    "# List of these objects to for loop the DATE cleanup.  \n",
    "# IF we wanted to acccess the report source from the combined df, we could add a column to each, with the report source\n",
    "\n",
    "# Initially had trouble by converting the dates to_datetime and then trying to drop the hour/min/sec.\n",
    "# Resolved by first converting DATE to str, dropping everything after \" \" (since all times were separated from date by a space)\n",
    "# And then subsequently converting the column to_datetime\n",
    "\n",
    "# This works, but can't be re-run unless above code blocks that create the dfs are also re-run (I think).  \n",
    "# Used print(i['DATE'].value_counts()) to confirm this came out correctly.  \n",
    "\n",
    "disengagement_dfs_list = [disengagement_df, first_df, autonomous_dis_df]\n",
    "\n",
    "for i in disengagement_dfs_list:\n",
    "    i['DATE'] = i['DATE'].astype(str)\n",
    "    i[\"DATE\"] = i[\"DATE\"].str.split(\" \", expand=True)[0]\n",
    "    i['DATE'] = pd.to_datetime(i['DATE'], errors='raise', dayfirst=True, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0279e6c6-8311-416c-9da4-1f00ffe034fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in disengagement_dfs_list:\\n    #print(i['Permit Number'].value_counts())\\n    print(i.shape)\\n\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in disengagement_dfs_list:\n",
    "    #print(i['Permit Number'].value_counts())\n",
    "    print(i.shape)\n",
    "'''\n",
    "\n",
    "# Operator-in-Vehicle = AVT Permit prefix\n",
    "# NVO = AVDT Permit Prefix.\n",
    "# I'm fairly certain splitting these into distinct columns for purposes of multi-indexed rows or columns is straightforward, \n",
    "# So am moving forward with data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1b8c862d-6ec4-4539-885c-530250ea8b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3x disengagement df's combined together into one, single column for all permit info\n",
    "combined_dis_df = pd.concat(disengagement_dfs_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481e0a0",
   "metadata": {},
   "source": [
    "# Data Cleaning and QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad80e1",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8ca9dd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPERATOR</th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>DATE</th>\n",
       "      <th>VIN NUMBER</th>\n",
       "      <th>NVO CAPABLE</th>\n",
       "      <th>DRIVER PRESENT</th>\n",
       "      <th>INITIATED BY</th>\n",
       "      <th>DISENGAGEMENT LOCATION</th>\n",
       "      <th>DESCRIPTION OF FACTS CAUSING DISENGAGEMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>During an exit/merge the test vehicle was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Exit/Merge Lane departure, due to the car miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Exit/Merge Lane departure, due to the car miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>During an exit/merge the test vehicle was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>The car should have stayed in the left lane, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Exit/Merge Lane departure, due to the car miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>During an exit/merge the test vehicle was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>During an exit/merge the test vehicle was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>During an exit/merge the test vehicle was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AIMOTIVE INC.</td>\n",
       "      <td>AVT036</td>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>JTDKN3DU9A0059509</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Test Driver</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>The car should have stayed in the left lane, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OPERATOR Permit Number       DATE         VIN NUMBER NVO CAPABLE  \\\n",
       "0  AIMOTIVE INC.        AVT036 2021-04-03  JTDKN3DU9A0059509          No   \n",
       "1  AIMOTIVE INC.        AVT036 2021-03-16  JTDKN3DU9A0059509          No   \n",
       "2  AIMOTIVE INC.        AVT036 2021-03-16  JTDKN3DU9A0059509          No   \n",
       "3  AIMOTIVE INC.        AVT036 2021-03-16  JTDKN3DU9A0059509          No   \n",
       "4  AIMOTIVE INC.        AVT036 2021-02-04  JTDKN3DU9A0059509          No   \n",
       "5  AIMOTIVE INC.        AVT036 2021-02-04  JTDKN3DU9A0059509          No   \n",
       "6  AIMOTIVE INC.        AVT036 2021-04-13  JTDKN3DU9A0059509          No   \n",
       "7  AIMOTIVE INC.        AVT036 2021-04-14  JTDKN3DU9A0059509          No   \n",
       "8  AIMOTIVE INC.        AVT036 2021-04-16  JTDKN3DU9A0059509          No   \n",
       "9  AIMOTIVE INC.        AVT036 2021-04-16  JTDKN3DU9A0059509          No   \n",
       "\n",
       "  DRIVER PRESENT INITIATED BY DISENGAGEMENT LOCATION  \\\n",
       "0            Yes  Test Driver                Freeway   \n",
       "1            Yes  Test Driver                Freeway   \n",
       "2            Yes  Test Driver                Freeway   \n",
       "3            Yes  Test Driver                Freeway   \n",
       "4            Yes  Test Driver                Freeway   \n",
       "5            Yes  Test Driver                Freeway   \n",
       "6            Yes  Test Driver                Freeway   \n",
       "7            Yes  Test Driver                Freeway   \n",
       "8            Yes  Test Driver                Freeway   \n",
       "9            Yes  Test Driver                Freeway   \n",
       "\n",
       "          DESCRIPTION OF FACTS CAUSING DISENGAGEMENT  \n",
       "0  During an exit/merge the test vehicle was goin...  \n",
       "1  Exit/Merge Lane departure, due to the car miss...  \n",
       "2  Exit/Merge Lane departure, due to the car miss...  \n",
       "3  During an exit/merge the test vehicle was goin...  \n",
       "4  The car should have stayed in the left lane, b...  \n",
       "5  Exit/Merge Lane departure, due to the car miss...  \n",
       "6  During an exit/merge the test vehicle was goin...  \n",
       "7  During an exit/merge the test vehicle was goin...  \n",
       "8  During an exit/merge the test vehicle was goin...  \n",
       "9  The car should have stayed in the left lane, b...  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dis_df.rename(columns = {\"Manufacturer\" : \"OPERATOR\",\n",
    "                                  \"DISENGAGEMENT\\nLOCATION\\n(Interstate, Freeway, Highway, Rural Road, Street, or Parking Facility)\" : \"DISENGAGEMENT LOCATION\", \n",
    "                                  \"DISENGAGEMENT INITIATED BY\\n(AV System, Test Driver, Remote Operator, or Passenger)\" : \"INITIATED BY\",\n",
    "                                  \"DRIVER PRESENT\\n(Yes or No)\" : \"DRIVER PRESENT\",\n",
    "                                  \"VEHICLE IS CAPABLE OF OPERATING WITHOUT A DRIVER\\n(Yes or No)\" : \"NVO CAPABLE\"}, inplace=True)\n",
    "\n",
    "combined_dis_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82967afa",
   "metadata": {},
   "source": [
    "Reduce Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "847b225c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Express Way', 'Freeway', 'Freeway ', 'HIGHWAY', 'HIghway', 'Highway', 'Interstate', 'Parking Facility', 'Parking facility', 'Rural Road', 'STREET', 'Street', 'Urban', 'freeway', 'street']\n",
      "15\n",
      "['AIMOTIVE INC.', 'APOLLO AUTONOMOUS DRIVING USA LLC', 'APPLE INC.', 'ARGO AI, LLC', 'AURORA OPERATIONS, INC.', 'AUTOX TECHNOLOGIES, INC', 'Apollo', 'BOSCH', 'CRUISE LLC', 'DEEPROUTE.AI', 'DIDI RESEARCH AMERICA LLC', 'DIDI RESEARCH AMERICA, LLC', 'Didi Research America', 'EASYMILE', 'GATIK AI INC', 'GATIK AI INC.', 'GHOST AUTONOMY INC', 'Gatik AI Inc', 'IMAGRY INC', 'IMAGRY INC ', 'IMAGRY INC.', 'INTEL CORPORATION', 'LYFT', 'MERCEDES-BENZ RESEARCH & DEVELOPMENT NORTH AMERICA, INC.', 'MOTIONAL AD, INC.', 'Motional AD, Inc.', 'NISSAN NORTH AMERICA, INC DBA ALLIANCE INNOVATION LAB', 'NURO, INC', 'NVIDIA', 'NVIDIA CORPORATION ', 'Nissan North America', 'Nuro Inc', 'PONY.AI, INC.', 'QCRAFT INC.', 'QUALCOMM TECHNOLOGIES, INC.', 'TOYOTA RESEARCH INSTITUTE', 'TOYOTA RESEARCH INSTITUTE, INC.', 'UATC, LLC', 'UDELV, INC.', 'VALEO NORTH AMERICA INC.', 'Valeo', 'Vueron Technology USA INC', 'WAYMO LLC', 'WERIDE CORP', 'WOVEN PLANET NORTH AMERICA, INC.', 'Waymo LLC', 'Woven by Toyota, U.S., Inc.', 'ZOOX INC', 'ZOOX, INC', 'Zoox, Inc', 'aiMotive Inc.']\n",
      "51\n",
      "(17712, 9)\n",
      "['EXPRESS WAY', 'FREEWAY', 'HIGHWAY', 'INTERSTATE', 'PARKING FACILITY', 'RURAL ROAD', 'STREET', 'URBAN']\n",
      "8\n",
      "['AIMOTIVE', 'APOLLO', 'APOLLO AUTONOMOUS DRIVING USA', 'APPLE', 'ARGO AI', 'AURORA OPERATIONS', 'AUTOX TECHNOLOGIES', 'BOSCH', 'CRUISE', 'DEEPROUTEAI', 'DIDI RESEARCH AMERICA', 'EASYMILE', 'GATIK AI', 'GHOST AUTONOMY', 'IMAGRY', 'INTEL CORPORATION', 'LYFT', 'MERCEDES-BENZ RESEARCH & DEVELOPMENT NORTH AMERICA', 'MOTIONAL AD', 'NISSAN NORTH AMERICA', 'NISSAN NORTH AMERICA  DBA ALLIANCE INNOVATION LAB', 'NURO', 'NVIDIA', 'NVIDIA CORPORATION', 'PONYAI', 'QCRAFT', 'QUALCOMM TECHNOLOGIES', 'TOYOTA RESEARCH INSTITUTE', 'UATC', 'UDELV', 'VALEO', 'VALEO NORTH AMERICA', 'VUERON TECHNOLOGY USA', 'WAYMO', 'WERIDE CORP', 'WOVEN BY TOYOTA US', 'WOVEN PLANET NORTH AMERICA', 'ZOOX']\n",
      "38\n",
      "(17712, 8)\n"
     ]
    }
   ],
   "source": [
    "# Kyle - Reduce duplicates\n",
    "\n",
    "def polish(df, column):\n",
    "   df[column]=df[column].str.upper() # Capitalize everything\n",
    "   df[column] = df[column].str.replace(\"[.,]\", \"\", regex=True) # Remove periods and commas \n",
    "   df[column] = df[column].str.replace(r'\\b(LLC|INC)\\b', '', regex=True)  # Remove \"LLC\" and \"INC\"\n",
    "   df[column]=df[column].str.rstrip() # Remove trailing whitespace\n",
    "\n",
    "   return df \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(sorted(combined_dis_df[\"DISENGAGEMENT LOCATION\"].unique()))\n",
    "print(combined_dis_df[\"DISENGAGEMENT LOCATION\"].nunique())\n",
    "print(sorted(combined_dis_df[\"OPERATOR\"].unique()))\n",
    "print(combined_dis_df[\"OPERATOR\"].nunique())\n",
    "print(combined_dis_df.shape)\n",
    "\n",
    "columns_to_clean = [\"DISENGAGEMENT LOCATION\", \"OPERATOR\"]\n",
    "\n",
    "for i in columns_to_clean:\n",
    "   combined_dis_df = polish(combined_dis_df, i)\n",
    "\n",
    "combined_dis_df.set_index(\"VIN NUMBER\", inplace=True)\n",
    "\n",
    "\n",
    "print(sorted(combined_dis_df[\"DISENGAGEMENT LOCATION\"].unique()))\n",
    "print(combined_dis_df[\"DISENGAGEMENT LOCATION\"].nunique())\n",
    "print(sorted(combined_dis_df[\"OPERATOR\"].unique()))\n",
    "print(combined_dis_df[\"OPERATOR\"].nunique())\n",
    "print(combined_dis_df.shape)\n",
    "\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c5b53d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22336\\2967033152.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombined_dis_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"DISENGAGEMENT LOCATION\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcapitalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_dis_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DISENGAGEMENT LOCATION\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\outdo\\anaconda3\\envs\\pyviz\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4285\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4286\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4287\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4288\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4289\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4290\u001b[0m         elif (\n\u001b[0;32m   4291\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4292\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\outdo\\anaconda3\\envs\\pyviz\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4413\u001b[0m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4414\u001b[0m             \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4415\u001b[0m             \u001b[0mlen_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4416\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen_cols\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4417\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Columns must be same length as key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4419\u001b[0m             \u001b[1;31m# align right-hand-side columns if self.columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4420\u001b[0m             \u001b[1;31m# is multi-index and self[key] is a sub-frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "combined_dis_df[\"DISENGAGEMENT LOCATION\"] = capitalize(combined_dis_df, \"DISENGAGEMENT LOCATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15953f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are \"Unnamed\" colums? Probably useless \"reserved\"\n",
    "# This and below are from kyle, and deal with the initial mileage_df\n",
    "unnamed_cols = ['Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21']\n",
    "for check in unnamed_cols:\n",
    "    non_null_count = mileage_df[check].notna().sum()\n",
    "    print(f'Number of non values in {check}: {non_null_count}')\n",
    "\n",
    "# Empty. Drop 'em\n",
    "mileage_df = mileage_df.drop(columns=unnamed_cols)\n",
    "mileage_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74187950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mileage_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning up types\n",
    "cast_as_float = [\n",
    "       'Annual Total of Disengagements', 'DEC-1', 'JAN', 'FEB', 'MAR', 'APR',\n",
    "       'MAY', 'JUN', 'JULY', 'AUG', 'SEP', 'OCT', 'NOV', 'Mileage Total',\n",
    "       ]\n",
    "\n",
    "for col in cast_as_float:\n",
    "    mileage_df[col] = mileage_df[col].apply(lambda x: x.replace(',', '').replace(' ', '') if isinstance(x, str) else x)\n",
    "    mileage_df[col] = mileage_df[col].astype(float)\n",
    "\n",
    "# Assuming df is your DataFrame and 'Column_Name' is the name of the column you want to convert to represent years\n",
    "mileage_df['Year'] = pd.to_datetime(mileage_df['Year']).dt.year\n",
    "mileage_df[\"Manufacturer\"] = mileage_df[\"Manufacturer\"].astype(str)\n",
    "\n",
    "\n",
    "print(mileage_df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QA the monthly vs sum values\n",
    "# Calculate the sum of values in the month columns for each row\n",
    "month_sums = mileage_df.iloc[:, 4:-2].sum(axis=1)  \n",
    "\n",
    "# Calculate the absolute difference between the sum of month columns and the \"Mileage Total\" column\n",
    "absolute_difference = abs(month_sums - mileage_df['Mileage Total'])\n",
    "\n",
    "# Check if the absolute difference is less than or equal to 2.0\n",
    "within_tolerance = absolute_difference <= 2.0\n",
    "fishy = (~within_tolerance).sum()\n",
    "print(\"Number of rows where months do not add up to within 1.0 of annual total:\", fishy)\n",
    "\n",
    "# Print rows where the absolute difference is not within 2.0\n",
    "# print(mileage_df[~within_tolerance])\n",
    "qa = mileage_df[~within_tolerance]\n",
    "print(f'Rows where MileageTotal is null: {qa[\"Mileage Total\"].isnull().sum()}')\n",
    "qa.head()\n",
    "\n",
    "\n",
    "# count all nulls \n",
    "print(mileage_df.isnull().sum())\n",
    "mileage_df.dropna(subset=['Mileage Total'], inplace=True)\n",
    "# Drops majority of other nulls\n",
    "print(mileage_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA Operators\n",
    "print(\"Number of unique operators: \", mileage_df[\"Manufacturer\"].nunique())\n",
    "mileage_df[\"Manufacturer\"] = mileage_df[\"Manufacturer\"].str.replace('.', '').str.replace(',', '').str.upper()\n",
    "\n",
    "operators = sorted(mileage_df[\"Manufacturer\"].unique())\n",
    "for value in operators:\n",
    "    print(value)\n",
    "\n",
    "# TODO: Mop up the last operators name alignment\n",
    "# mileage_df[\"Manufacturer\"] = mileage_df[\"Manufacturer\"].str.replace('long_duplicates', 'shorter_version')\n",
    "print(\"Actual number of unique operators: \", mileage_df[\"Manufacturer\"].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_mileage = mileage_df[(mileage_df[\"Mileage Total\"] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f725d",
   "metadata": {},
   "source": [
    "### GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175270c1-e22f-46f8-85d3-ca955f111c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  autonomous miles necessarily.  Need to look at data sources further.\n",
    "\n",
    "# TODO: Drop zeroes? Probably.\n",
    "\n",
    "#### Histogram: miles driven / VIN ######\n",
    "vin = px.histogram(nonzero_mileage,\n",
    "             x='Mileage Total', color=\"Manufacturer\", title=\"Autonomous Mileage by Vehicle (2021-2023)\", nbins=50)\n",
    "vin.update_layout(xaxis_title='Vehicle Mileage', yaxis_title='Number of Vehicles')\n",
    "vin.show()\n",
    "\n",
    "#### Histogram: miles driven / Operator ######\n",
    "manufacturer_miles_sum = nonzero_mileage.groupby('Manufacturer')['Mileage Total'].sum().reset_index()\n",
    "\n",
    "fig = px.histogram(manufacturer_miles_sum, x='Mileage Total', title='Total Miles Driven Per Operator (2021-2023)',\n",
    "                   labels={'Mileage Total': 'Total Miles Driven'},  nbins=100)  # Adjust nbins as needed\n",
    "fig.update_layout(yaxis_title='Operators')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### WANT: Would be absolutley sick if we could start with the VINs histogram and animated into the by Operator graph...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kyle - Word cloud of Disengagement descriptions\n",
    "text = combined_dis_df[\"DESCRIPTION OF FACTS CAUSING DISENGAGEMENT\"].values \n",
    "\n",
    "stop_words = [\"vehicle\", \"/n\", \"Non\", \"road\"] + list(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords = stop_words, background_color=\"white\", colormap=\"CMRmap\").generate(str(text))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a11d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b666339",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Miles driven donut by operator? only a few DOMINATE the space.\n",
    "## No need? Show by above graphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if any manufacturers have multiple permit numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunburst of mileage by month? \n",
    "# what sotry? weather vehicles can/can't run in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scatter of number of VINs and total miles? by manufacturer\n",
    "# Bubble size number of disengagements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec884ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scatter of x=miles driven, y=disengagements, by VIN? color by manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13563e0e-aaf7-46b4-95ba-61b35fb0aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Total Miles driven per year ####\n",
    "# Aggregate the sum of \"Mileage Total\" by \"Year\" and \"Manufacturer\"\n",
    "agg_df = mileage_df.groupby(['Manufacturer', 'Year'])['Mileage Total'].sum().reset_index()\n",
    "\n",
    "# Filter to include only data for the top 10 operators\n",
    "top_10_operators = mileage_df.groupby('Manufacturer')['Mileage Total'].sum().nlargest(10).index\n",
    "top_miles = agg_df[agg_df['Manufacturer'].isin(top_10_operators)]\n",
    "manufacturer_order = agg_df.groupby('Manufacturer')['Mileage Total'].sum().sort_values(ascending=False).index\n",
    "\n",
    "\n",
    "# Create the bar plot\n",
    "fig = px.bar(top_miles, x='Year', y='Mileage Total', color='Manufacturer', text=\"Manufacturer\", title='Annual Autonomous Mileage Totals', category_orders={'Manufacturer': manufacturer_order})\n",
    "fig.update_layout(xaxis_title='Year', yaxis_title='Mileage Total')\n",
    "fig.update_xaxes(tickvals=[2021, 2022, 2023])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e31cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Duplicate of above, but line\n",
    "\n",
    "# Create line plot\n",
    "fig = px.line(top_miles, x='Year', y='Mileage Total', color='Manufacturer', text=\"Manufacturer\", title='Annual Mileage Total by Operator')\n",
    "fig.update_layout(xaxis_title='Year', yaxis_title='Mileage Total')\n",
    "fig.update_xaxes(tickvals=[2021, 2022, 2023])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636f319-51e9-4e44-83ca-a67ed5931dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DISENGAGEMENTS PER THOUSAND MILES DRIVEN\n",
    "# Makes most sense to show by year on a per-company basis. \n",
    "\n",
    "# Group by manufacturer - get VIN count, total disengagments and total miles\n",
    "dptm = nonzero_mileage.groupby(['Manufacturer', 'Year']).agg({'Mileage Total': 'sum',\n",
    "                                                              'Annual Total of Disengagements': 'sum',\n",
    "                                                              'VIN NUMBER': 'nunique'}).reset_index()\n",
    "# Calculate DPTM\n",
    "dptm[\"Disengagements/Thousand Miles\"] = (dptm['Annual Total of Disengagements'] / (dptm['Mileage Total'] / 1000))\n",
    "\n",
    "# Lowest DPTM Operators\n",
    "smoothest_operators = dptm.groupby('Manufacturer')['Disengagements/Thousand Miles'].sum().nsmallest(10).index\n",
    "# Simple Yearly Aggregate of DPTM per Operator\n",
    "agg_2 = dptm.groupby(['Manufacturer', 'Year'])['Disengagements/Thousand Miles'].sum().reset_index()\n",
    "# agg_2 filtered by smoothest operators (best 10)\n",
    "lowest_disengage_rate = agg_2[agg_2['Manufacturer'].isin(smoothest_operators)]\n",
    "\n",
    "# DPTM df filtered down to 10 best @ DPTM\n",
    "dptm_filtered_10 = dptm[dptm['Manufacturer'].isin(smoothest_operators)]\n",
    "\n",
    "dptm_total = nonzero_mileage.groupby(['Manufacturer']).agg({'Mileage Total': 'sum',\n",
    "                                                              'Annual Total of Disengagements': 'sum'}).reset_index()\n",
    "dptm_total[\"Disengagements/Thousand Miles\"] = (dptm_total['Annual Total of Disengagements'] / (dptm_total['Mileage Total'] / 1000))\n",
    "\n",
    "dptm_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6445dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do the correlation thing on DPTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ecf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graphing DPTM\n",
    "# Mehhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh tells no story, would be a lot cooler with more years of data\n",
    "fig = px.scatter(dptm, x=\"Mileage Total\", y=\"Annual Total of Disengagements\", \n",
    "                 size=\"VIN NUMBER\", color=\"Manufacturer\",\n",
    "                 animation_frame=\"Year\", animation_group=\"Manufacturer\",\n",
    "                 range_x=[0, dptm[\"Mileage Total\"].max() * 1.1],  # Adjust range for x-axis\n",
    "                 range_y=[0, dptm[\"Annual Total of Disengagements\"].max() * 1.1],  # Adjust range for y-axis\n",
    "                 labels={\"Mileage Total\": \"Annual Mileage\", \"Annual Total of Disengagements\": \"Annual Total of Disengagements\", \"VIN NUMBER\": \"Number of Vehicles\", \"Manufacturer\": \"Manufacturer\", \"Year\": \"Year\"}\n",
    "                )\n",
    "fig.update_layout(title='Total Disengagments vs Total Mileage [Bubble size = No. of Vehicles]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0504ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graphing RATE of dsengagements against total miles\n",
    "fig = px.scatter(dptm, x=\"Mileage Total\", y=\"Disengagements/Thousand Miles\", color=\"Manufacturer\")\n",
    "fig.update_layout(title='Average Annual Disengagements Per Thousand Miles v. Total Mileage - All Opertors')\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(dptm_total, x=\"Mileage Total\", y=\"Disengagements/Thousand Miles\", color=\"Manufacturer\")\n",
    "fig.update_layout(title='Average Disengagements Per Thousand Miles v. Total Mileage - All Opertors (2021-2023)')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca512f5-8fa9-42f5-a2e2-1618433530ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: mileage_df.shape = (4360, 46)\n",
    "print(mileage_df.columns)\n",
    "mileage_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ff0c4-56c1-407b-8dd4-75b087e8b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO: disengagement_df.shape = (23579, 10)\n",
    "print(disengagement_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ea08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
