{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from pdfplumber.utils.pdfinternals import resolve_and_decode, resolve\n",
    "from pprint import pprint\n",
    "import os\n",
    "import io \n",
    "import zipfile\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''These are all of the fields which I think are relevant: Operator, time and place, vehicle details, damage report, \n",
    "other party details, description, mode, conditions. NOTE: many fields which are positive are marked with a BLANK \" \", \n",
    "while negatives marked with \"None\".'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_fields = ['MANufACTuRERS NAME','BuSINESS NAME',\n",
    "              'DATE Of ACCIDENT','Time of Accident','AM','PM',\n",
    "              'VEhICLE YEAR','MAkE','MODEL',\n",
    "              'section 2  accident infoRmation.0','section 2  accident infoRmation.1.0','section 2  accident infoRmation.1.1.0','section 2  accident infoRmation.1.1.1.0','section 2  accident infoRmation.1.1.1.1',\n",
    "              'Moving', 'Stopped in Traffic', 'Pedestrian', 'Bicyclist', 'undefined', 'Other',\n",
    "              'NuMBER Of VEhICLES INVOLVED',\n",
    "              'Unknown','None','minor','Moderate','major',\n",
    "              'Left Rear 1','Rear Bumper','Right Rear 1','Left Rear 2','Left Rear 3','Right Rear 2','Right Rear 3',\n",
    "              'Left Rear Passenger 1','Left Rear Passenger 2','Right Rear Passenger 1','Right Rear Passenger 2',\n",
    "              'Left Rear Passenger 3','Left Rear Passenger 4','Right Rear Passenger 3','Right Rear Passenger 4',\n",
    "              'Front Driver Side 1','Front Driver Side 2','Front Passenger Side 1','Front Passenger Side 2',\n",
    "              'Front Driver Side 3','Front Driver Side 4','Front Passenger Side 3','Front Passenger Side 4',\n",
    "              'Left Front Corner 1','Left Front Corner 2','Right Front Corner 1', 'Right Front Corner 2',\n",
    "              'Left Front Corner 3','Front Bumper','Right Front Corner 3',\n",
    "              'Moving_2', 'Stopped in Traffic_2','Pedestrian_2','Bicyclist_2','undefined_2','Other_2',\n",
    "              'ADDRESS_2.1.0.1','Autonomous Mode','Conventional Mode',\n",
    "              'WEATHER A 1','WEATHER A 2','WEATHER B 1','WEATHER B 2','WEATHER C 1','WEATHER C 2',\n",
    "              'WEATHER D 1','WEATHER D 2','WEATHER E 1','WEATHER E 2','WEATHER F 1','WEATHER F 2','WEATHER G 1','WEATHER G 2', \n",
    "              'LIGHTING A 1','LIGHTING A 2','LIGHTING B 1','LIGHTING B 2','LIGHTING C 1','LIGHTING C 2',\n",
    "              'LIGHTING D 1','LIGHTING D 2','LIGHTING E 1','LIGHTING E 2',\n",
    "              'ROADWAY A 1','ROADWAY A 2','ROADWAY B 1','ROADWAY B 2','ROADWAY C 1', 'ROADWAY C 2','ROADWAY D 1','ROADWAY D 2', \n",
    "              'ROAD CONDITIONS A 1','ROAD CONDITIONS A 2','ROAD CONDITIONS B 1','ROAD CONDITIONS B 2', 'ROAD CONDITIONS C 1','ROAD CONDITIONS C 2',\n",
    "              'ROAD CONDITIONS D 1','ROAD CONDITIONS D 2','ROAD CONDITIONS E 1', 'ROAD CONDITIONS E 2', 'ROAD CONDITIONS F 1', 'ROAD CONDITIONS F 2', \n",
    "              'ROAD CONDITIONS G 1', 'ROAD CONDITIONS G 2', 'ROAD CONDITIONS H 1', 'ROAD CONDITIONS H 2',\n",
    "              'MOVEMENT A 1','MOVEMENT A 2','MOVEMENT  B 1', 'MOVEMENT  B 2','MOVEMENT C 1','MOVEMENT C 2', 'MOVEMENT  D 1','MOVEMENT  D 2', \n",
    "              'MOVEMENT  E 1','MOVEMENT  E 2', 'MOVEMENT  F 1', 'MOVEMENT  F 2', 'MOVEMENT  G 1','MOVEMENT  G 2', 'MOVEMENT  H 1','MOVEMENT  H 2', \n",
    "              'MOVEMENT  I 1', 'MOVEMENT  I 2', 'MOVEMENT J 1', 'MOVEMENT J 2', 'MOVEMENT  K 1', 'MOVEMENT  K 2', 'MOVEMENT  L 1', 'MOVEMENT  L 2',\n",
    "              'MOVEMENT  M 1', 'MOVEMENT  M 2','MOVEMENT  N 1', 'MOVEMENT  N 2', 'MOVEMENT  O 1', 'MOVEMENT  O 2',\n",
    "              'MOVEMENT  P 1', 'MOVEMENT  P 2', 'MOVEMENT  Q 1', 'MOVEMENT  Q 2', 'MOVEMENT  R 1', 'MOVEMENT  R 2',\n",
    "              'TYPE A 1', 'TYPE A 2', 'TYPE B 1', 'TYPE B 2','TYPE C 1','TYPE C 2','TYPE D 1','TYPE D 2','TYPE E 1','TYPE E 2','TYPE F 1','TYPE F 2','TYPE G 1','TYPE G 2','TYPE H 1','TYPE H 2',\n",
    "              'OTHER A YES','OTHER A NO','OTHER B','OTHER C','OTHER D','OTHER E','OTHER F','OTHER G',\n",
    "              'OTHER H YES','OTHER H NO','OTHER I','OTHER J','OTHER K','OTHER L']\n",
    "\n",
    "conditions_only = ['WEATHER A 1','WEATHER A 2','WEATHER B 1','WEATHER B 2','WEATHER C 1','WEATHER C 2',\n",
    "              'WEATHER D 1','WEATHER D 2','WEATHER E 1','WEATHER E 2','WEATHER F 1','WEATHER F 2','WEATHER G 1','WEATHER G 2', \n",
    "              'LIGHTING A 1','LIGHTING A 2','LIGHTING B 1','LIGHTING B 2','LIGHTING C 1','LIGHTING C 2',\n",
    "              'LIGHTING D 1','LIGHTING D 2','LIGHTING E 1','LIGHTING E 2',\n",
    "              'ROADWAY A 1','ROADWAY A 2','ROADWAY B 1','ROADWAY B 2','ROADWAY C 1', 'ROADWAY C 2','ROADWAY D 1','ROADWAY D 2', \n",
    "              'ROAD CONDITIONS A 1','ROAD CONDITIONS A 2','ROAD CONDITIONS B 1','ROAD CONDITIONS B 2', 'ROAD CONDITIONS C 1','ROAD CONDITIONS C 2',\n",
    "              'ROAD CONDITIONS D 1','ROAD CONDITIONS D 2','ROAD CONDITIONS E 1', 'ROAD CONDITIONS E 2', 'ROAD CONDITIONS F 1', 'ROAD CONDITIONS F 2', \n",
    "              'ROAD CONDITIONS G 1', 'ROAD CONDITIONS G 2', 'ROAD CONDITIONS H 1', 'ROAD CONDITIONS H 2',\n",
    "              'MOVEMENT A 1','MOVEMENT A 2','MOVEMENT  B 1', 'MOVEMENT  B 2','MOVEMENT C 1','MOVEMENT C 2', 'MOVEMENT  D 1','MOVEMENT  D 2', \n",
    "              'MOVEMENT  E 1','MOVEMENT  E 2', 'MOVEMENT  F 1', 'MOVEMENT  F 2', 'MOVEMENT  G 1','MOVEMENT  G 2', 'MOVEMENT  H 1','MOVEMENT  H 2', \n",
    "              'MOVEMENT  I 1', 'MOVEMENT  I 2', 'MOVEMENT J 1', 'MOVEMENT J 2', 'MOVEMENT  K 1', 'MOVEMENT  K 2', 'MOVEMENT  L 1', 'MOVEMENT  L 2',\n",
    "              'MOVEMENT  M 1', 'MOVEMENT  M 2','MOVEMENT  N 1', 'MOVEMENT  N 2', 'MOVEMENT  O 1', 'MOVEMENT  O 2',\n",
    "              'MOVEMENT  P 1', 'MOVEMENT  P 2', 'MOVEMENT  Q 1', 'MOVEMENT  Q 2', 'MOVEMENT  R 1', 'MOVEMENT  R 2',\n",
    "              'TYPE A 1', 'TYPE A 2', 'TYPE B 1', 'TYPE B 2','TYPE C 1','TYPE C 2','TYPE D 1','TYPE D 2','TYPE E 1','TYPE E 2','TYPE F 1','TYPE F 2','TYPE G 1','TYPE G 2','TYPE H 1','TYPE H 2',\n",
    "              'OTHER A YES''OTHER A NO','OTHER B','OTHER C','OTHER D','OTHER E','OTHER F','OTHER G',\n",
    "              'OTHER H YES','OTHER H NO','OTHER I','OTHER J','OTHER K','OTHER L']\n",
    "\n",
    "damage_only = ['Autonomous Mode','Unknown','None','minor','Moderate','major',\n",
    "              'Left Rear 1','Rear Bumper','Right Rear 1','Left Rear 2','Left Rear 3','Right Rear 2','Right Rear 3',\n",
    "              'Left Rear Passenger 1','Left Rear Passenger 2','Right Rear Passenger 1','Right Rear Passenger 2',\n",
    "              'Left Rear Passenger 3','Left Rear Passenger 4','Right Rear Passenger 3','Right Rear Passenger 4',\n",
    "              'Front Driver Side 1','Front Driver Side 2','Front Passenger Side 1','Front Passenger Side 2',\n",
    "              'Front Driver Side 3','Front Driver Side 4','Front Passenger Side 3','Front Passenger Side 4',\n",
    "              'Left Front Corner 1','Left Front Corner 2','Right Front Corner 1', 'Right Front Corner 2',\n",
    "              'Left Front Corner 3','Front Bumper','Right Front Corner 3',]\n",
    "\n",
    "geo_only = ['Operator','Business',\n",
    "              'Date_of_Accident','Time_of_accident','AM','PM',\n",
    "              'location', 'city', 'county',\n",
    "              'state','zip']\n",
    "\n",
    "description_cols = [\"location\", \"In_autonomy\", 'Description']\n",
    "\n",
    "\n",
    "# Rename columns:\n",
    "rename_dict = {\"Section 1 Manufacturers information. enter manufacturer's NAME\": 'Operator',\n",
    "               \"enter BUSINESS NAME\": 'Business',\n",
    "               \"Section 2. Accident information vehicle one enter DATE Of ACCIDENT\": \"Date_of_Accident\",\n",
    "               \"enter time of accident\": \"Time_of_accident\",\n",
    "               \"Time of accident. Mark if Ay M.\":\"AM\",\n",
    "               \"Mark if P M.\":\"PM\",\n",
    "               \"enter address and location of accident.\":\"location\",\n",
    "               \"enter city of accident\":\"city\",\n",
    "               \"enter county of accident.\":\"county\",\n",
    "               \"enter state of accident.\":\"state\",\n",
    "               \"enter zip code of accident.\":\"zip\",\n",
    "               \"describe accident details.\":\"Description\",\n",
    "               \"section 5. accident details description. Mark if Autonomous Mode.\":\"In_autonomy\",\n",
    "               \"Mark if Conventional Mode\":\"Conventional_mode\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function read the filed name, alternate field name, and field values\n",
    "def parse_field_helper(form_data, field, prefix=None):\n",
    "    \"\"\" appends any PDF AcroForm field/value pairs in `field` to provided `form_data` list\n",
    "\n",
    "        if `field` has child fields, those will be parsed recursively.\n",
    "    \"\"\"\n",
    "    resolved_field = field.resolve()\n",
    "    field_name = '.'.join(filter(lambda x: x, [prefix, resolve_and_decode(resolved_field.get(\"T\"))]))\n",
    "    if \"Kids\" in resolved_field:\n",
    "        for kid_field in resolved_field[\"Kids\"]:\n",
    "            parse_field_helper(form_data, kid_field, prefix=field_name)\n",
    "    if \"T\" in resolved_field or \"TU\" in resolved_field:\n",
    "        # \"T\" is a field-name, but it's sometimes absent.\n",
    "        # \"TU\" is the \"alternate field name\" and is often more human-readable\n",
    "        # your PDF may have one, the other, or both.\n",
    "        alternate_field_name = resolve_and_decode(resolved_field.get(\"TU\")) if resolved_field.get(\"TU\") else None\n",
    "        field_value = resolve_and_decode(resolved_field[\"V\"]) if 'V' in resolved_field else None\n",
    "\n",
    "        # Remove non-printable characters and trailing spaces - This affects every Cruise file.\n",
    "        field_name = ''.join(char for char in field_name if char.isprintable()).strip()\n",
    "        alternate_field_name = ''.join(char for char in alternate_field_name if char.isprintable()).strip() if alternate_field_name else None\n",
    "        field_value = ''.join(char for char in field_value if char.isprintable()).strip() if field_value else None\n",
    "        \n",
    "        form_data.append([field_name, alternate_field_name, field_value])\n",
    "\n",
    "# Define filtering criteria \n",
    "def find_important_tuples(tuple, search_condition):\n",
    "    # Check if the first element of the tuple is in the search condition list\n",
    "    return tuple[0] in search_condition\n",
    "\n",
    "# Loop over all pdfs and add entries.  Keyword can search foles for specific name\n",
    "def extract_from_zip(zip_file_path, list_of_pdf_fields, keyword=None):\n",
    "    collisions = []\n",
    "    counter = 0\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        for filename in zip_ref.namelist():\n",
    "            # Check if the current item is a pdf file\n",
    "            if filename.endswith('.pdf') and (keyword is None or keyword in filename):\n",
    "                print(f'Extracting: {filename}...')\n",
    "                # Read PDF from zip file\n",
    "                with zip_ref.open(filename, 'r') as pdf_file:\n",
    "                    pdf_data = io.BytesIO(pdf_file.read())\n",
    "\n",
    "                # Open each pdf\n",
    "                pdf = pdfplumber.open(pdf_data)\n",
    "                form_data = []\n",
    "                # identify fields\n",
    "                fields = resolve(pdf.doc.catalog[\"AcroForm\"])[\"Fields\"]\n",
    "                # For each field, run the pdf parsing function to extract adta and add it to form_data list\n",
    "                for field in fields:\n",
    "                    parse_field_helper(form_data, field)\n",
    "\n",
    "                # Filter the long list of tuples [all_fields, geo_only, conditions_only, damage_only]\n",
    "                filtered_list = [tuple for tuple in form_data if find_important_tuples(tuple, list_of_pdf_fields)]\n",
    "                \n",
    "                data_dict = {}\n",
    "                # Set df sturcture so each pdf is one row - alt_text is column name, value is vlaue]\n",
    "                # Populate the dictionary with values from filtered_list\n",
    "                for tuple in filtered_list:\n",
    "                    column_name = tuple[1]  # ---------------------  [0] = Field name, [1] = Alt name, switching sometimes helpful but may require changing lists above.\n",
    "                    row_value = tuple[2]\n",
    "                    data_dict[column_name] = row_value\n",
    "                \n",
    "                # Create DataFrame from the dictionary\n",
    "                collision_report = pd.DataFrame([data_dict])\n",
    "                collisions.append(collision_report)\n",
    "                print('Done.')\n",
    "                counter += 1\n",
    "    \n",
    "    print(f\"Extracted data from {counter} collision reports.\")\n",
    "    df = pd.concat(collisions)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_bools(df):\n",
    "    for column in df.columns:\n",
    "        # Replace empty strings and None with specific values\n",
    "        df[column] = df[column].replace({\"\": 1, None: 0, \"Yes\": 1, \"Off\": 0})\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = \"data/collisions/Collision_PDFs.zip\"\n",
    "# read in all the data once.\n",
    "all_collisions_df = extract_from_zip(path_to_zip, all_fields)\n",
    "all_collisions_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "all_collisions_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Fill Mfg name\n",
    "all_collisions_df['Operator'] = all_collisions_df['Operator'].fillna(all_collisions_df['Business'])\n",
    "\n",
    "all_rows = all_collisions_df.shape[0]\n",
    "\n",
    "# Drop rows not in autonomy\n",
    "auto_collisions_df = all_collisions_df[all_collisions_df['Conventional_mode'] != 1]\n",
    "\n",
    "# Calculate the number of rows dropped\n",
    "non_autonomy = all_rows - auto_collisions_df.shape[0]\n",
    "print(f\"Number of rows not in autonomy dropped: {non_autonomy}\")\n",
    "\n",
    "\n",
    "# TODO: Change the conditions column names (light, weather, etc) into the alt_filed name (tuple[1]) for human readability. - NOTE: partially solved by using Alt_text instead of text. Still should be cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of True values in each column\n",
    "mode_counts = all_collisions_df[['In_autonomy', 'Conventional_mode']].sum()\n",
    "\n",
    "# Create a bar plot using Plotly Express\n",
    "fig = px.bar(x=mode_counts.index, y=mode_counts.values, labels={'x': 'Autonomy', 'y': 'Count'}, \n",
    "             title='Collision Records in Autonomy', color=mode_counts.index,\n",
    "             color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "fig.write_image(\"Images/In_autonomy.jpg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_collisions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh locations dataframe\n",
    "collision_locations = auto_collisions_df[geo_only]\n",
    "collision_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns:\n",
    "collision_locations.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Fix date times\n",
    "collision_locations['Date_of_Accident'] = pd.to_datetime(collision_locations['Date_of_Accident'], errors='coerce')\n",
    "\n",
    "# Get the initial number of rows\n",
    "initial_rows = collision_locations.shape[0]\n",
    "\n",
    "# Drop NaN values in 'Time_of_accident' column with an empty string\n",
    "collision_locations.dropna(subset=['Time_of_accident'], inplace=True)\n",
    "# Find additional bad time data\n",
    "# unique_times = collision_locations['Time_of_accident'].astype(str).unique()\n",
    "# Sort the unique times and print them\n",
    "# sorted_unique_times = sorted(unique_times)\n",
    "# print(sorted_unique_times)\n",
    "# Drop Zoox 06_08_2022 where no time is entered.\n",
    "collision_locations = collision_locations[collision_locations['Time_of_accident'] != 0]\n",
    "\n",
    "# Calculate the number of rows dropped\n",
    "rows_dropped = initial_rows - collision_locations.shape[0]\n",
    "print(f\"Number of rows dropped: {rows_dropped}\")\n",
    "\n",
    "\n",
    "# Fix Woven Planet Empty fields\n",
    "collision_locations.loc[collision_locations['Operator'] == 0, [\"Operator\", \"Business\"]] = \"Woven Planet\"\n",
    "\n",
    "# Fix Ghost Autonomy fields\n",
    "collision_locations.loc[collision_locations['Business'] == 'same', [\"Operator\", \"Business\"]] = \"Ghost Autonomy\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'Time_of_accident' column to string type\n",
    "collision_locations['Time_of_accident'] = collision_locations['Time_of_accident'].astype(str)\n",
    "collision_locations[['hour', 'minute']] = collision_locations['Time_of_accident'].str.extract(r'(\\d+):(\\d+)')\n",
    "collision_locations[['hour', 'minute']] = collision_locations[['hour', 'minute']].astype(int)\n",
    "\n",
    "# Add 12 hours to hour component if PM is True and hour is less than 12\n",
    "collision_locations['hour'] = collision_locations.apply(lambda row: row['hour'] + 12 if row['PM'] == 1 and row['hour'] < 12 else row['hour'], axis=1)\n",
    "\n",
    "#Rehoin hours and mins into 24hr time\n",
    "collision_locations['Time_of_accident_24hr'] = pd.to_datetime(collision_locations[['hour', 'minute']].astype(str).agg(':'.join, axis=1), format='%H:%M').dt.time\n",
    "# Drop calc fileds\n",
    "collision_locations.drop(columns=(['Time_of_accident', 'AM', 'PM', 'hour', 'minute']),inplace=True)\n",
    "\n",
    "collision_locations.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv\n",
    "# Specify the full path where you want to save the CSV file\n",
    "csv_file_path = 'data/collisions/dataframes/locations/crash_locations.csv'\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "collision_locations.to_csv(csv_file_path, index=False)\n",
    "collision_locations.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh locations dataframe\n",
    "descriptions_df = auto_collisions_df[description_cols]\n",
    "descriptions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "descriptions_df.to_csv('data/collisions/dataframes/descriptions/descriptions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @JackP TODO: Collision heatmap and severity\n",
    "\n",
    "# Read in damage data by tuple[0], filed name:\n",
    "damage_df = extract_from_zip(path_to_zip, damage_only)\n",
    "damage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Collisions & disengagements grouped bar by mfg (on main)\n",
    "damage_df = clean_bools(damage_df)\n",
    "\n",
    "damage_df.head()\n",
    "damage_df.to_csv('data/collisions/dataframes/damage_map/damage.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyviz2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
