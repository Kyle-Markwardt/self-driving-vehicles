{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from pdfplumber.utils.pdfinternals import resolve_and_decode, resolve\n",
    "from pprint import pprint\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''These are all of the fields which I think are relevant: Operator, time and place, vehicle details, damage report, \n",
    "other party details, description, mode, conditions. NOTE: many fields which are positive are marked with a BLANK \" \", \n",
    "while negatives marked with \"None\".'''\n",
    "\n",
    "# Files location\n",
    "collisions_path = \"data/collisions\"\n",
    "\n",
    "all_fields = ['MANufACTuRERS NAME','BuSINESS NAME',\n",
    "              'DATE Of ACCIDENT','Time of Accident','AM','PM',\n",
    "              'VEhICLE YEAR','MAkE','MODEL',\n",
    "              'section 2  accident infoRmation.0','section 2  accident infoRmation.1.0','section 2  accident infoRmation.1.1.0','section 2  accident infoRmation.1.1.1.0','section 2  accident infoRmation.1.1.1.1',\n",
    "              'Moving', 'Stopped in Traffic', 'Pedestrian', 'Bicyclist', 'undefined', 'Other',\n",
    "              'NuMBER Of VEhICLES INVOLVED',\n",
    "              'Unknown','None','minor','Moderate','major',\n",
    "              'Left Rear 1','Rear Bumper','Right Rear 1','Left Rear 2','Left Rear 3','Right Rear 2','Right Rear 3',\n",
    "              'Left Rear Passenger 1','Left Rear Passenger 2','Right Rear Passenger 1','Right Rear Passenger 2',\n",
    "              'Left Rear Passenger 3','Left Rear Passenger 4','Right Rear Passenger 3','Right Rear Passenger 4',\n",
    "              'Front Driver Side 1','Front Driver Side 2','Front Passenger Side 1','Front Passenger Side 2',\n",
    "              'Front Driver Side 3','Front Driver Side 4','Front Passenger Side 3','Front Passenger Side 4',\n",
    "              'Left Front Corner 1','Left Front Corner 2','Right Front Corner 1', 'Right Front Corner 2',\n",
    "              'Left Front Corner 3','Front Bumper','Right Front Corner 3',\n",
    "              'Moving_2', 'Stopped in Traffic_2','Pedestrian_2','Bicyclist_2','undefined_2','Other_2',\n",
    "              'ADDRESS_2.1.0.1','Autonomous Mode','Conventional Mode',\n",
    "              'WEATHER A 1','WEATHER A 2','WEATHER B 1','WEATHER B 2','WEATHER C 1','WEATHER C 2',\n",
    "              'WEATHER D 1','WEATHER D 2','WEATHER E 1','WEATHER E 2','WEATHER F 1','WEATHER F 2','WEATHER G 1','WEATHER G 2', \n",
    "              'LIGHTING A 1','LIGHTING A 2','LIGHTING B 1','LIGHTING B 2','LIGHTING C 1','LIGHTING C 2',\n",
    "              'LIGHTING D 1','LIGHTING D 2','LIGHTING E 1','LIGHTING E 2',\n",
    "              'ROADWAY A 1','ROADWAY A 2','ROADWAY B 1','ROADWAY B 2','ROADWAY C 1', 'ROADWAY C 2','ROADWAY D 1','ROADWAY D 2', \n",
    "              'ROAD CONDITIONS A 1','ROAD CONDITIONS A 2','ROAD CONDITIONS B 1','ROAD CONDITIONS B 2', 'ROAD CONDITIONS C 1','ROAD CONDITIONS C 2',\n",
    "              'ROAD CONDITIONS D 1','ROAD CONDITIONS D 2','ROAD CONDITIONS E 1', 'ROAD CONDITIONS E 2', 'ROAD CONDITIONS F 1', 'ROAD CONDITIONS F 2', \n",
    "              'ROAD CONDITIONS G 1', 'ROAD CONDITIONS G 2', 'ROAD CONDITIONS H 1', 'ROAD CONDITIONS H 2',\n",
    "              'MOVEMENT A 1','MOVEMENT A 2','MOVEMENT  B 1', 'MOVEMENT  B 2','MOVEMENT C 1','MOVEMENT C 2', 'MOVEMENT  D 1','MOVEMENT  D 2', \n",
    "              'MOVEMENT  E 1','MOVEMENT  E 2', 'MOVEMENT  F 1', 'MOVEMENT  F 2', 'MOVEMENT  G 1','MOVEMENT  G 2', 'MOVEMENT  H 1','MOVEMENT  H 2', \n",
    "              'MOVEMENT  I 1', 'MOVEMENT  I 2', 'MOVEMENT J 1', 'MOVEMENT J 2', 'MOVEMENT  K 1', 'MOVEMENT  K 2', 'MOVEMENT  L 1', 'MOVEMENT  L 2',\n",
    "              'MOVEMENT  M 1', 'MOVEMENT  M 2','MOVEMENT  N 1', 'MOVEMENT  N 2', 'MOVEMENT  O 1', 'MOVEMENT  O 2',\n",
    "              'MOVEMENT  P 1', 'MOVEMENT  P 2', 'MOVEMENT  Q 1', 'MOVEMENT  Q 2', 'MOVEMENT  R 1', 'MOVEMENT  R 2',\n",
    "              'TYPE A 1', 'TYPE A 2', 'TYPE B 1', 'TYPE B 2','TYPE C 1','TYPE C 2','TYPE D 1','TYPE D 2','TYPE E 1','TYPE E 2','TYPE F 1','TYPE F 2','TYPE G 1','TYPE G 2','TYPE H 1','TYPE H 2',\n",
    "              'OTHER A YES','OTHER A NO','OTHER B','OTHER C','OTHER D','OTHER E','OTHER F','OTHER G',\n",
    "              'OTHER H YES','OTHER H NO','OTHER I','OTHER J','OTHER K','OTHER L']\n",
    "\n",
    "conditions_only = ['WEATHER A 1','WEATHER A 2','WEATHER B 1','WEATHER B 2','WEATHER C 1','WEATHER C 2',\n",
    "              'WEATHER D 1','WEATHER D 2','WEATHER E 1','WEATHER E 2','WEATHER F 1','WEATHER F 2','WEATHER G 1','WEATHER G 2', \n",
    "              'LIGHTING A 1','LIGHTING A 2','LIGHTING B 1','LIGHTING B 2','LIGHTING C 1','LIGHTING C 2',\n",
    "              'LIGHTING D 1','LIGHTING D 2','LIGHTING E 1','LIGHTING E 2',\n",
    "              'ROADWAY A 1','ROADWAY A 2','ROADWAY B 1','ROADWAY B 2','ROADWAY C 1', 'ROADWAY C 2','ROADWAY D 1','ROADWAY D 2', \n",
    "              'ROAD CONDITIONS A 1','ROAD CONDITIONS A 2','ROAD CONDITIONS B 1','ROAD CONDITIONS B 2', 'ROAD CONDITIONS C 1','ROAD CONDITIONS C 2',\n",
    "              'ROAD CONDITIONS D 1','ROAD CONDITIONS D 2','ROAD CONDITIONS E 1', 'ROAD CONDITIONS E 2', 'ROAD CONDITIONS F 1', 'ROAD CONDITIONS F 2', \n",
    "              'ROAD CONDITIONS G 1', 'ROAD CONDITIONS G 2', 'ROAD CONDITIONS H 1', 'ROAD CONDITIONS H 2',\n",
    "              'MOVEMENT A 1','MOVEMENT A 2','MOVEMENT  B 1', 'MOVEMENT  B 2','MOVEMENT C 1','MOVEMENT C 2', 'MOVEMENT  D 1','MOVEMENT  D 2', \n",
    "              'MOVEMENT  E 1','MOVEMENT  E 2', 'MOVEMENT  F 1', 'MOVEMENT  F 2', 'MOVEMENT  G 1','MOVEMENT  G 2', 'MOVEMENT  H 1','MOVEMENT  H 2', \n",
    "              'MOVEMENT  I 1', 'MOVEMENT  I 2', 'MOVEMENT J 1', 'MOVEMENT J 2', 'MOVEMENT  K 1', 'MOVEMENT  K 2', 'MOVEMENT  L 1', 'MOVEMENT  L 2',\n",
    "              'MOVEMENT  M 1', 'MOVEMENT  M 2','MOVEMENT  N 1', 'MOVEMENT  N 2', 'MOVEMENT  O 1', 'MOVEMENT  O 2',\n",
    "              'MOVEMENT  P 1', 'MOVEMENT  P 2', 'MOVEMENT  Q 1', 'MOVEMENT  Q 2', 'MOVEMENT  R 1', 'MOVEMENT  R 2',\n",
    "              'TYPE A 1', 'TYPE A 2', 'TYPE B 1', 'TYPE B 2','TYPE C 1','TYPE C 2','TYPE D 1','TYPE D 2','TYPE E 1','TYPE E 2','TYPE F 1','TYPE F 2','TYPE G 1','TYPE G 2','TYPE H 1','TYPE H 2',\n",
    "              'OTHER A YES''OTHER A NO','OTHER B','OTHER C','OTHER D','OTHER E','OTHER F','OTHER G',\n",
    "              'OTHER H YES','OTHER H NO','OTHER I','OTHER J','OTHER K','OTHER L']\n",
    "\n",
    "damage_only = ['Unknown','None','minor','Moderate','major',\n",
    "              'Left Rear 1','Rear Bumper','Right Rear 1','Left Rear 2','Left Rear 3','Right Rear 2','Right Rear 3',\n",
    "              'Left Rear Passenger 1','Left Rear Passenger 2','Right Rear Passenger 1','Right Rear Passenger 2',\n",
    "              'Left Rear Passenger 3','Left Rear Passenger 4','Right Rear Passenger 3','Right Rear Passenger 4',\n",
    "              'Front Driver Side 1','Front Driver Side 2','Front Passenger Side 1','Front Passenger Side 2',\n",
    "              'Front Driver Side 3','Front Driver Side 4','Front Passenger Side 3','Front Passenger Side 4',\n",
    "              'Left Front Corner 1','Left Front Corner 2','Right Front Corner 1', 'Right Front Corner 2',\n",
    "              'Left Front Corner 3','Front Bumper','Right Front Corner 3',]\n",
    "\n",
    "geo_only = ['MANufACTuRERS NAME','BuSINESS NAME',\n",
    "              'DATE Of ACCIDENT','Time of Accident','AM','PM',\n",
    "              'section 2  accident infoRmation.0','section 2  accident infoRmation.1.0','section 2  accident infoRmation.1.1.0',\n",
    "              'section 2  accident infoRmation.1.1.1.0','section 2  accident infoRmation.1.1.1.1']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_field_helper(form_data, field, prefix=None):\n",
    "    \"\"\" appends any PDF AcroForm field/value pairs in `field` to provided `form_data` list\n",
    "\n",
    "        if `field` has child fields, those will be parsed recursively.\n",
    "    \"\"\"\n",
    "    resolved_field = field.resolve()\n",
    "    field_name = '.'.join(filter(lambda x: x, [prefix, resolve_and_decode(resolved_field.get(\"T\"))]))\n",
    "    if \"Kids\" in resolved_field:\n",
    "        for kid_field in resolved_field[\"Kids\"]:\n",
    "            parse_field_helper(form_data, kid_field, prefix=field_name)\n",
    "    if \"T\" in resolved_field or \"TU\" in resolved_field:\n",
    "        # \"T\" is a field-name, but it's sometimes absent.\n",
    "        # \"TU\" is the \"alternate field name\" and is often more human-readable\n",
    "        # your PDF may have one, the other, or both.\n",
    "        alternate_field_name  = resolve_and_decode(resolved_field.get(\"TU\")) if resolved_field.get(\"TU\") else None\n",
    "        field_value = resolve_and_decode(resolved_field[\"V\"]) if 'V' in resolved_field else None\n",
    "        \n",
    "        # Remove non-printable characters and trailing spaces - This affects every Cruise file.\n",
    "        field_name = ''.join(char for char in field_name if char.isprintable()).strip()\n",
    "        alternate_field_name = ''.join(char for char in alternate_field_name if char.isprintable()).strip() if alternate_field_name else None\n",
    "        field_value = ''.join(char for char in field_value if char.isprintable()).strip() if field_value else None\n",
    "        \n",
    "        form_data.append([field_name, alternate_field_name, field_value])\n",
    "\n",
    "\n",
    "# Define filtering criteria \n",
    "def find_important_tuples(tuple, search_condition):\n",
    "    # Check if the first element of the tuple is in the search condition list\n",
    "    return tuple[0] in search_condition\n",
    "\n",
    "\n",
    "# Loop over all pdfs and add entries.  Keyword added for interrogating Cruise, specifically\n",
    "def extract_from_pdf(list_of_pdf_fields, keyword=None):\n",
    "    # List of collisions\n",
    "    collisions = []\n",
    "    # Create an empty dictionary to store data for DataFrame\n",
    "    counter = 0\n",
    "    for filename in os.listdir(collisions_path):\n",
    "        # Check if the current item is a file (not a subdirectory)\n",
    "        if os.path.isfile(os.path.join(collisions_path, filename)) and (keyword is None or keyword in filename):\n",
    "            data_dict = {}\n",
    "            print(f'Extracting:{collisions_path}/{filename}...')\n",
    "\n",
    "\n",
    "            # Open each pdf\n",
    "            pdf = pdfplumber.open(f'{collisions_path}/{filename}')\n",
    "            # initialize fom data list\n",
    "            form_data = []\n",
    "            # identify fields\n",
    "            fields = resolve(pdf.doc.catalog[\"AcroForm\"])[\"Fields\"]\n",
    "\n",
    "            # For each field, run the pdf parsing function to extract adta and add it to form_data list\n",
    "            for field in fields:\n",
    "                parse_field_helper(form_data, field)\n",
    "                \n",
    "            # Filter the long list of tuples [all_fields, geo_only, conditions_only, damage_only]\n",
    "            filtered_list = [tuple for tuple in form_data if find_important_tuples(tuple, list_of_pdf_fields)]\n",
    "\n",
    "            # Set df sturcture so each pdf is one row - alt_text is column name, value is vlaue]\n",
    "            # Populate the dictionary with values from filtered_list\n",
    "            for tuple in filtered_list:\n",
    "                column_name = tuple[1]\n",
    "                row_value = tuple[2]\n",
    "                data_dict[column_name] = row_value\n",
    "\n",
    "            # Create DataFrame from the dictionary\n",
    "            collision_report = pd.DataFrame([data_dict])\n",
    "            collisions.append(collision_report)\n",
    "            print('Done.')\n",
    "            counter +=1 \n",
    "\n",
    "    print(f\"Extracted data from {counter} collision reports.\")\n",
    "            \n",
    "    df = pd.concat(collisions)    \n",
    "    # Reset the index of the DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_locations = extract_from_pdf(geo_only)\n",
    "collision_locations.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = collision_locations\n",
    "temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns:\n",
    "rename_dict = {\"Section 1. Manufacturers information. Enter manufacturer's name\": 'Operator',\n",
    "               \"enter BUSINESS NAME\": 'Business',\n",
    "               \"Section 2. Accident information vehicle one enter DATE Of ACCIDENT\": \"Date_of_Accident\",\n",
    "               \"enter time of accident\": \"Time_of_accident\",\n",
    "               \"Time of accident. Mark if Ay M.\":\"AM\",\n",
    "               \"Mark if P M.\":\"PM\",\n",
    "               \"enter address and location of accident.\":\"address\",\n",
    "               \"enter city of accident\":\"city\",\n",
    "               \"enter county of accident.\":\"county\",\n",
    "               \"enter state of accident.\":\"state\",\n",
    "               \"enter zip code of accident.\":\"zip\",\n",
    "               \"enter address and location of accident.\":\"Location\",\n",
    "               \"describe accident details.\":\"Description\",\n",
    "               \"section 5. accident details description. Mark if Autonomous Mode.\":\"In_autonomy\",\n",
    "               \"Mark if Conventional Mode\":\"Conventional_mode\"}\n",
    "\n",
    "collision_locations.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Fix date times\n",
    "collision_locations['Date_of_Accident'] = pd.to_datetime(collision_locations['Date_of_Accident'], errors='coerce')\n",
    "\n",
    "# Get the initial number of rows\n",
    "initial_rows = collision_locations.shape[0]\n",
    "\n",
    "# Drop NaN values in 'Time_of_accident' column with an empty string\n",
    "collision_locations.dropna(subset=['Time_of_accident'], inplace=True)\n",
    "\n",
    "# Calculate the number of rows dropped\n",
    "rows_dropped = initial_rows - collision_locations.shape[0]\n",
    "print(f\"Number of rows dropped: {rows_dropped}\")\n",
    "\n",
    "\n",
    "\n",
    "collision_locations['hour'],collision_locations['minute']= collision_locations['Time_of_accident'].split(':')\n",
    "\n",
    "\n",
    "\n",
    "# if pm = true  and hour <12, add 12 to hh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Time_of_accident' column to string type\n",
    "collision_locations['Time_of_accident'] = collision_locations['Time_of_accident'].astype(str)\n",
    "\n",
    "# if HH in HH:MM is > 12, then subtract 12.\n",
    "# HH == 00, then add 12\n",
    "\n",
    "# Update time format based on AM and PM columns\n",
    "for index, row in collision_locations.iterrows():\n",
    "    time_str = row['Time_of_accident']\n",
    "    if row['AM'] == ' ':\n",
    "        # If AM is checked, assume it's AM\n",
    "        time_str += ' AM'\n",
    "    elif row['PM'] == ' ':\n",
    "        # If PM is checked, assume it's PM\n",
    "        time_str += ' PM'\n",
    "    else:\n",
    "        # Assume it's PM\n",
    "        time_str += ' PM'\n",
    "\n",
    "    # Update the time string\n",
    "    collision_locations.at[index, 'Time_of_accident'] = time_str\n",
    "\n",
    "# Fix Time column\n",
    "collision_locations['Time_of_accident'] = collision_locations['Time_of_accident'].str.strip()\n",
    "# Drop Am/PM\n",
    "collision_locations.drop(columns=['AM', 'PM'], inplace=True)\n",
    "# Convert back to datetime\n",
    "collision_locations['Time_of_accident'] = pd.to_datetime(collision_locations['Time_of_accident'], format='%I:%M %p')\n",
    "# Convert 'Time_of_accident' column to 24-hr HH:MM\n",
    "collision_locations['Time_of_accident'] = collision_locations['Time_of_accident'].dt.strftime('%H:%M')\n",
    "\n",
    "# TODO: Cruise 040122 datetime is being parsed wrong. Should be 00:43 AM\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_locations.head(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv\n",
    "# Specify the full path where you want to save the CSV file\n",
    "csv_file_path = 'data/collisions/dataframes/locations/crash_locations.csv'\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "collision_locations.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to change \" \"s into True and \"None\" into False - found different workadround for AM/PM\n",
    "# TODO: Change the conditions column names (light, weather, etc) into the alt_filed name (tuple[1]) for human readability. - NOTE: partially solved by using Alt_text instead of text. Still should be cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: @Kyle - create descriptions dataframe. Save and read into main for wordcloud\n",
    "description_cols = [\"section 2  accident infoRmation.0\", \"Autonomous Mode\", 'ADDRESS_2.1.0.1']\n",
    "descriptions_df = extract_from_pdf(description_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = descriptions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_df.rename(columns=rename_dict, inplace=True)\n",
    "descriptions_df[\"In_autonomy\"] = descriptions_df[\"In_autonomy\"].replace({\"\": 1, None: 0})\n",
    "\n",
    "\n",
    "descriptions_df.to_csv('data/collisions/dataframes/descriptions/descriptions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @JackP TODO: Collision heatmap and severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Collisions & disengagements grouped bar by mfg (on main)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyviz2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
